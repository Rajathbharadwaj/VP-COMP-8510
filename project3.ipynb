{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find chessboard corners in one or both images.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the stereo images\n",
    "left_img = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "right_img = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the number of inner corners of the chessboard (for example, an 8x8 chessboard has 7x7 inner corners)\n",
    "pattern_size = (7, 7)\n",
    "\n",
    "# Find the chessboard corners in both images\n",
    "ret_left, corners_left = cv2.findChessboardCorners(left_img, pattern_size)\n",
    "ret_right, corners_right = cv2.findChessboardCorners(right_img, pattern_size)\n",
    "\n",
    "if ret_left and ret_right:\n",
    "    # Refine the detected corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    cv2.cornerSubPix(left_img, corners_left, (11, 11), (-1, -1), criteria)\n",
    "    cv2.cornerSubPix(right_img, corners_right, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "    # These are your 2D points in each image\n",
    "    points_2d_left = corners_left\n",
    "    points_2d_right = corners_right\n",
    "else:\n",
    "    print(\"Could not find chessboard corners in one or both images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "right_img = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.findChessboardCorners(left_img, (7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load Images\n",
    "img1 = cv2.imread(\"first_image.jpg\")\n",
    "img2 = cv2.imread(\"second_image.jpg\")\n",
    "\n",
    "# 2. Given 3D points and corresponding 2D points\n",
    "# Replace with your data\n",
    "object_points_left = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "])\n",
    "\n",
    "object_points_right = np.array([\n",
    "    [24.3, 0, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "])\n",
    "\n",
    "# 3. Get 2D points (e.g., clicked on the images or detected automatically)\n",
    "# For demonstration, let's assume they are:\n",
    "image_points_left = np.array([\n",
    "    # Example points, replace with detected coordinates\n",
    "    [100, 100],\n",
    "    [200, 100],\n",
    "    [200, 200],\n",
    "    [100, 200],\n",
    "    [100, 50],\n",
    "    [200, 50],\n",
    "    [200, 250],\n",
    "    [100, 250]\n",
    "])\n",
    "\n",
    "image_points_right = image_points_left + 5  # Just for demo, consider it's shifted by 5 pixels\n",
    "\n",
    "# 4. Camera Calibration\n",
    "_, camera_matrix_left, dist_coeff_left, _, _ = cv2.calibrateCamera([object_points], [image_points_left], img1.shape[:2], None, None)\n",
    "_, camera_matrix_right, dist_coeff_right, _, _ = cv2.calibrateCamera([object_points], [image_points_right], img2.shape[:2], None, None)\n",
    "\n",
    "# 5. Calculate Fundamental Matrix\n",
    "F, _ = cv2.findFundamentalMat(image_points_left, image_points_right, cv2.FM_LMEDS)\n",
    "\n",
    "# 6. Triangulation to get 3D coordinates\n",
    "def triangulate_points(p1, p2, m1, m2):\n",
    "    return cv2.triangulatePoints(m1, m2, p1.T, p2.T).T\n",
    "\n",
    "# 7. Mouse Callback Function\n",
    "def callback(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        p1 = np.array([x, y, 1]).reshape(3, 1)\n",
    "        \n",
    "        # Draw a + sign at p\n",
    "        cv2.drawMarker(img1, (x, y), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10)\n",
    "        \n",
    "        # Compute epipolar line on right image\n",
    "        l2 = np.dot(F, p1)\n",
    "        x0, y0 = map(int, [0, -l2[2]/l2[1]])\n",
    "        x1, y1 = map(int, [img2.shape[1], -(l2[2] + l2[0]*img2.shape[1]) / l2[1]])\n",
    "        \n",
    "        # Draw the line on the right image\n",
    "        cv2.line(img2, (x0, y0), (x1, y1), (0, 255, 0), 1)\n",
    "        \n",
    "        # This is a naive way to find a corresponding point. In real-world applications, you'd use better matching techniques.\n",
    "        p2 = np.array([x+5, y, 1]).reshape(3, 1)  # Assuming the shift is 5 pixels for demonstration\n",
    "        \n",
    "        # Draw a + sign at p'\n",
    "        cv2.drawMarker(img2, (x+5, y), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10)\n",
    "        \n",
    "        # Get 3D coordinates\n",
    "        point_3d_homo = triangulate_points(p1.T, p2.T, camera_matrix_left, camera_matrix_right)\n",
    "        point_3d = (point_3d_homo / point_3d_homo[3])[:3].ravel()\n",
    "        \n",
    "        print(f\"3D Point: {point_3d}\")\n",
    "        \n",
    "        cv2.imshow('Left Image', img1)\n",
    "        cv2.imshow('Right Image', img2)\n",
    "\n",
    "# Create window and bind function to window\n",
    "cv2.namedWindow('Left Image')\n",
    "cv2.setMouseCallback('Left Image', callback)\n",
    "\n",
    "cv2.imshow('Left Image', img1)\n",
    "cv2.imshow('Right Image', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in left image: [(253, 378), (85, 351), (92, 200), (260, 192), (407, 356), (294, 378), (301, 196), (413, 220)]\n",
      "Points in right image: [(257, 404), (106, 365), (113, 197), (269, 177), (475, 376), (312, 402), (321, 184), (480, 214)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Global variables\n",
    "point_list = []\n",
    "point_count = 0\n",
    "\n",
    "# Mouse callback function\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global point_list, point_count\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(temp_img, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Image', temp_img)\n",
    "        point_list.append((x, y))\n",
    "        point_count += 1\n",
    "\n",
    "        if point_count == 18:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Read your image\n",
    "img_left = cv2.imread('im1.jpeg')\n",
    "img_right = cv2.imread('im2.jpeg')\n",
    "\n",
    "# For left image\n",
    "temp_img = img_left.copy()\n",
    "cv2.imshow('Image', temp_img)\n",
    "cv2.setMouseCallback('Image', select_points)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "points_2d_left = point_list.copy()  # save the points for the left image\n",
    "point_list.clear()  # clear the list to store points for the right image\n",
    "point_count = 0  # reset point count\n",
    "\n",
    "# For right image\n",
    "temp_img = img_right.copy()\n",
    "cv2.imshow('Image', temp_img)\n",
    "cv2.setMouseCallback('Image', select_points)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "points_2d_right = point_list\n",
    "\n",
    "print(\"Points in left image:\", points_2d_left)\n",
    "print(\"Points in right image:\", points_2d_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m points_2d_right \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([(\u001b[39m475\u001b[39m, \u001b[39m373\u001b[39m), (\u001b[39m312\u001b[39m, \u001b[39m402\u001b[39m), (\u001b[39m323\u001b[39m, \u001b[39m185\u001b[39m), (\u001b[39m478\u001b[39m, \u001b[39m214\u001b[39m)], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Camera Calibration\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m ret, mtx_left, dist_left, rvecs_left, tvecs_left \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([world_points_left], [points_2d_left], (\u001b[39m1280\u001b[39;49m, \u001b[39m720\u001b[39;49m), intrinsic_matrix, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     38\u001b[0m ret, mtx_right, dist_right, rvecs_right, tvecs_right \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([world_points_right], [points_2d_right], (\u001b[39m1280\u001b[39m, \u001b[39m720\u001b[39m), intrinsic_matrix, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Calculate Fundamental Matrix\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "world_points_left = np.array([\n",
    "    [  0.        ,  14.46666667,   3.8       ],\n",
    "       [  0.        , 217.        ,   3.8       ],\n",
    "       [  0.        , 217.        ,  18.8       ],\n",
    "       [  0.        ,  14.46666667,  18.8       ],\n",
    "], dtype=np.float32)\n",
    "\n",
    "world_points_right = np.array([\n",
    " [394.        ,   0.        ,   3.8       ],\n",
    "       [ 53.50617284,   0.        ,   3.8       ],\n",
    "       [ 53.50617284,   0.        ,  18.8       ],\n",
    "       [394.        ,   0.        ,  18.8       ],\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Image dimensions\n",
    "width = 1280\n",
    "height = 720\n",
    "\n",
    "# Approximate intrinsic matrix\n",
    "fx = width\n",
    "fy = height\n",
    "cx = width / 2\n",
    "cy = height / 2\n",
    "intrinsic_matrix = np.array([[fx, 0, cx],\n",
    "                             [0, fy, cy],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "points_2d_left = np.array([(251, 379), (84, 352), (91, 201), (259, 190)], dtype=np.float32)\n",
    "points_2d_right = np.array([(475, 373), (312, 402), (323, 185), (478, 214)], dtype=np.float32)\n",
    "\n",
    "# Camera Calibration\n",
    "ret, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera([world_points_left], [points_2d_left], (1280, 720), intrinsic_matrix, None)\n",
    "ret, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera([world_points_right], [points_2d_right], (1280, 720), intrinsic_matrix, None)\n",
    "\n",
    "# Calculate Fundamental Matrix\n",
    "F, _ = cv2.findFundamentalMat(points_2d_left, points_2d_right, cv2.FM_8POINT)\n",
    "\n",
    "print(\"Fundamental Matrix F:\\n\", F)\n",
    "\n",
    "# Callback function for mouse click on the left image\n",
    "def on_click_left(event, x, y, flags, param):\n",
    "    global points_2d_left, points_2d_right, mtx_left, mtx_right, F\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pt = np.array([x, y, 1]).reshape(3, 1)\n",
    "        epiline = np.dot(F, pt).ravel()\n",
    "\n",
    "        # Draw the epipolar line on the right image\n",
    "        cv2.line(right_img, (0, int(-epiline[2] / epiline[1])), (right_img.shape[1], int(-(epiline[2] + epiline[0] * right_img.shape[1]) / epiline[1])), (0, 0, 255), 1)\n",
    "\n",
    "        # Draw \"+\" on the left image\n",
    "        cv2.drawMarker(left_img, (x, y), (0, 255, 0), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Show the images again\n",
    "        cv2.imshow('Left Image', left_img)\n",
    "        cv2.imshow('Right Image', right_img)\n",
    "\n",
    "# Callback function for mouse click on the right image\n",
    "def on_click_right(event, x, y, flags, param):\n",
    "    global points_2d_left, points_2d_right, mtx_left, mtx_right, F\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pt = np.array([x, y, 1]).reshape(3, 1)\n",
    "        epiline = np.dot(F.T, pt).ravel()\n",
    "\n",
    "        # Draw the epipolar line on the left image\n",
    "        cv2.line(left_img, (0, int(-epiline[2] / epiline[1])), (left_img.shape[1], int(-(epiline[2] + epiline[0] * left_img.shape[1]) / epiline[1])), (0, 0, 255), 1)\n",
    "\n",
    "        # Draw \"+\" on the right image\n",
    "        cv2.drawMarker(right_img, (x, y), (0, 255, 0), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Show the images again\n",
    "        cv2.imshow('Left Image', left_img)\n",
    "        cv2.imshow('Right Image', right_img)\n",
    "\n",
    "# Load your stereo images\n",
    "left_img = cv2.imread('im1.jpeg')\n",
    "right_img = cv2.imread('im2.jpeg')\n",
    "\n",
    "cv2.namedWindow('Left Image')\n",
    "cv2.setMouseCallback('Left Image', on_click_left)\n",
    "cv2.namedWindow('Right Image')\n",
    "cv2.setMouseCallback('Right Image', on_click_right)\n",
    "\n",
    "cv2.imshow('Left Image', left_img)\n",
    "cv2.imshow('Right Image', right_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 3D points:\n",
      "[[ 0.   1.5  3.8]\n",
      " [ 0.  22.5  3.8]\n",
      " [ 0.  22.5 18.8]\n",
      " [ 0.   1.5 18.8]\n",
      " [24.3  0.   3.8]\n",
      " [ 3.3  0.   3.8]\n",
      " [ 3.3  0.  18.8]\n",
      " [24.3  0.  18.8]]\n",
      "\n",
      "Scaled 3D points:\n",
      "[[  0.          14.46666667   3.8       ]\n",
      " [  0.         217.           3.8       ]\n",
      " [  0.         217.          18.8       ]\n",
      " [  0.          14.46666667  18.8       ]\n",
      " [394.           0.           3.8       ]\n",
      " [ 53.50617284   0.           3.8       ]\n",
      " [ 53.50617284   0.          18.8       ]\n",
      " [394.           0.          18.8       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define your 3D and 2D points\n",
    "points_3d = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "])\n",
    "\n",
    "points_2d_left = np.array([(251, 379), (84, 352), (91, 201), (259, 190)])\n",
    "points_2d_right = np.array([(475, 373), (312, 402), (323, 185), (478, 214)])\n",
    "points_2d = np.vstack((points_2d_left, points_2d_right))\n",
    "\n",
    "# Compute 3D range\n",
    "range_3d = np.max(points_3d, axis=0) - np.min(points_3d, axis=0)\n",
    "\n",
    "# Compute 2D range\n",
    "range_2d = np.max(points_2d, axis=0) - np.min(points_2d, axis=0)\n",
    "\n",
    "# Compute scaling factors\n",
    "scale_factors = range_2d / range_3d[:2]\n",
    "\n",
    "# Scale the 3D points\n",
    "points_3d_scaled = points_3d.copy()\n",
    "points_3d_scaled[:, 0] *= scale_factors[0]\n",
    "points_3d_scaled[:, 1] *= scale_factors[1]\n",
    "\n",
    "print(\"Original 3D points:\")\n",
    "print(points_3d)\n",
    "print(\"\\nScaled 3D points:\")\n",
    "print(points_3d_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,  14.46666667,   3.8       ],\n",
       "       [  0.        , 217.        ,   3.8       ],\n",
       "       [  0.        , 217.        ,  18.8       ],\n",
       "       [  0.        ,  14.46666667,  18.8       ],\n",
       "       [394.        ,   0.        ,   3.8       ],\n",
       "       [ 53.50617284,   0.        ,   3.8       ],\n",
       "       [ 53.50617284,   0.        ,  18.8       ],\n",
       "       [394.        ,   0.        ,  18.8       ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_3d_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m flags \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     37\u001b[0m flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCALIB_FIX_INTRINSIC\n\u001b[0;32m---> 38\u001b[0m ret, mtx_left, dist_left, rvecs_left, tvecs_left \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([scaled_3d_points[:\u001b[39m4\u001b[39;49m]], [points_2d_left], (width, height), intrinsic_matrix, dist_coeff, flags\u001b[39m=\u001b[39;49mflags)\n\u001b[1;32m     39\u001b[0m ret, mtx_right, dist_right, rvecs_right, tvecs_right \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([scaled_3d_points[\u001b[39m4\u001b[39m:]], [points_2d_right], (width, height), intrinsic_matrix, dist_coeff, flags\u001b[39m=\u001b[39mflags)\n\u001b[1;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLeft Camera Matrix:\u001b[39m\u001b[39m\"\u001b[39m, mtx_left)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Image dimensions\n",
    "width = 1280\n",
    "height = 720\n",
    "\n",
    "# Initialize intrinsic matrix\n",
    "fx = width\n",
    "fy = height\n",
    "cx = width / 2\n",
    "cy = height / 2\n",
    "intrinsic_matrix = np.array([[fx, 0, cx],\n",
    "                             [0, fy, cy],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Initial distortion coefficients\n",
    "dist_coeff = np.zeros((5,1), dtype=np.float32)\n",
    "\n",
    "# Your 3D and 2D points\n",
    "scaled_3d_points = np.array([\n",
    "    [0, 14.46666667, 3.8],\n",
    "    [0, 217, 3.8],\n",
    "    [0, 217, 18.8],\n",
    "    [0, 14.46666667, 18.8],\n",
    "    [394, 0, 3.8],\n",
    "    [53.50617284, 0, 3.8],\n",
    "    [53.50617284, 0, 18.8],\n",
    "    [394, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "points_2d_left = np.array([(251, 379), (84, 352), (91, 201), (259, 190)], dtype=np.float32)\n",
    "points_2d_right = np.array([(475, 373), (312, 402), (323, 185), (478, 214)], dtype=np.float32)\n",
    "\n",
    "# Camera Calibration\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "ret, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera([scaled_3d_points[:4]], [points_2d_left], (width, height), intrinsic_matrix, dist_coeff, flags=flags)\n",
    "ret, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera([scaled_3d_points[4:]], [points_2d_right], (width, height), intrinsic_matrix, dist_coeff, flags=flags)\n",
    "\n",
    "print(\"Left Camera Matrix:\", mtx_left)\n",
    "print(\"Right Camera Matrix:\", mtx_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1173: error: (-2:Unspecified error) in function 'void cvFindExtrinsicCameraParams2(const CvMat *, const CvMat *, const CvMat *, const CvMat *, CvMat *, CvMat *, int)'\n> DLT algorithm needs at least 6 points for pose estimation from 3D-2D point correspondences. (expected: 'count >= 6'), where\n>     'count' is 4\n> must be greater than or equal to\n>     '6' is 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# Initial camera matrix - assuming roughly central principal point and aspect ratio = 1\u001b[39;00m\n\u001b[1;32m     39\u001b[0m initial_camera_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m1000\u001b[39m, \u001b[39m0\u001b[39m, image_size[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m, image_size[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]])\n\u001b[0;32m---> 40\u001b[0m ret, mtx_left, dist_left, rvecs_left, tvecs_left \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([world_points[:\u001b[39m4\u001b[39;49m]], [points_2d_left], image_size, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     41\u001b[0m ret, mtx_right, dist_right, rvecs_right, tvecs_right \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([world_points[\u001b[39m4\u001b[39m:]], [points_2d_right], image_size, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Compute the fundamental matrix\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1173: error: (-2:Unspecified error) in function 'void cvFindExtrinsicCameraParams2(const CvMat *, const CvMat *, const CvMat *, const CvMat *, CvMat *, CvMat *, int)'\n> DLT algorithm needs at least 6 points for pose estimation from 3D-2D point correspondences. (expected: 'count >= 6'), where\n>     'count' is 4\n> must be greater than or equal to\n>     '6' is 6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading the Images\n",
    "left_img = cv2.imread(\"im1.jpeg\")\n",
    "right_img = cv2.imread(\"im2.jpeg\")\n",
    "\n",
    "# Known 3D world points and 2D image points\n",
    "world_points = np.array([\n",
    "    [0, 1.5, 0],\n",
    "    [0, 22.5, 0],\n",
    "    [0, 22.5, 0],\n",
    "    [0, 1.5, 0],\n",
    "    [24.3, 0, 0],\n",
    "    [3.3, 0, 0],\n",
    "    [3.3, 0, 0],\n",
    "    [24.3, 0, 0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "points_2d_left = np.array([\n",
    "    [251, 379], \n",
    "    [84, 352], \n",
    "    [91, 201], \n",
    "    [259, 190]\n",
    "], dtype=np.float32)\n",
    "\n",
    "points_2d_right = np.array([\n",
    "    [475, 373],\n",
    "    [312, 402], \n",
    "    [323, 185], \n",
    "    [478, 214]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Camera calibration\n",
    "# Define image size\n",
    "image_size = (left_img.shape[1], left_img.shape[0])  # (width, height)\n",
    "\n",
    "# Initial camera matrix - assuming roughly central principal point and aspect ratio = 1\n",
    "initial_camera_matrix = np.array([[1000, 0, image_size[0]/2], [0, 1000, image_size[1]/2], [0, 0, 1]])\n",
    "ret, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera([world_points[:4]], [points_2d_left], image_size, None, None)\n",
    "ret, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera([world_points[4:]], [points_2d_right], image_size, None, None)\n",
    "\n",
    "\n",
    "# Compute the fundamental matrix\n",
    "F, _ = cv2.findFundamentalMat(points_2d_left, points_2d_right, cv2.FM_LMEDS)\n",
    "\n",
    "def mouse_event_handler(event, x, y, flags, param):\n",
    "    global left_img, right_img\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if param == \"left\":\n",
    "            cv2.circle(left_img, (x,y), 5, (0,0,255), -1)\n",
    "            \n",
    "            # Calculate epipolar line on the right image\n",
    "            line = cv2.computeCorrespondEpilines(np.array([[x, y]]).reshape(-1,1,2), 1, F)\n",
    "            line = line.squeeze()\n",
    "            start = (0, int(-line[2]/line[1]))\n",
    "            end = (right_img.shape[1], int((-line[2]-line[0]*right_img.shape[1])/line[1]))\n",
    "            \n",
    "            cv2.line(right_img, start, end, (0,255,0), 1)\n",
    "            \n",
    "            # Triangulation to compute 3D coordinates\n",
    "            P1 = np.hstack((mtx_left, np.array([[0], [0], [0]])))\n",
    "            P2 = np.hstack((mtx_right, np.array([[0], [0], [0]])))\n",
    "\n",
    "            point_4d_hom = cv2.triangulatePoints(P1, P2, np.array([[x], [y]]), np.array([[x], [y]]))  # You may need to adjust the corresponding point in the right image\n",
    "            point_3d = point_4d_hom / point_4d_hom[3]\n",
    "            print(\"3D Point:\", point_3d[:3])\n",
    "\n",
    "        elif param == \"right\":\n",
    "            # Similar steps for the right image...\n",
    "            cv2.circle(right_img, (x,y), 5, (0,0,255), -1)\n",
    "            \n",
    "            # Calculate epipolar line on the right image\n",
    "            line = cv2.computeCorrespondEpilines(np.array([[x, y]]).reshape(-1,1,2), 1, F)\n",
    "            line = line.squeeze()\n",
    "            start = (0, int(-line[2]/line[1]))\n",
    "            end = (right_img.shape[1], int((-line[2]-line[0]*right_img.shape[1])/line[1]))\n",
    "            \n",
    "            cv2.line(right_img, start, end, (0,255,0), 1)\n",
    "            \n",
    "            # Triangulation to compute 3D coordinates\n",
    "            P1 = np.hstack((mtx_left, np.array([[0], [0], [0]])))\n",
    "            P2 = np.hstack((mtx_right, np.array([[0], [0], [0]])))\n",
    "\n",
    "            point_4d_hom = cv2.triangulatePoints(P1, P2, np.array([[x], [y]]), np.array([[x], [y]]))  # You may need to adjust the corresponding point in the right image\n",
    "            point_3d = point_4d_hom / point_4d_hom[3]\n",
    "            print(\"3D Point:\", point_3d[:3])\n",
    "            pass\n",
    "\n",
    "        cv2.imshow(\"Left Image\", left_img)\n",
    "        cv2.imshow(\"Right Image\", right_img)\n",
    "\n",
    "cv2.namedWindow(\"Left Image\")\n",
    "cv2.namedWindow(\"Right Image\")\n",
    "\n",
    "cv2.setMouseCallback(\"Left Image\", mouse_event_handler, \"left\")\n",
    "cv2.setMouseCallback(\"Right Image\", mouse_event_handler, \"right\")\n",
    "\n",
    "cv2.imshow(\"Left Image\", left_img)\n",
    "cv2.imshow(\"Right Image\", right_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the left and right images in grayscale\n",
    "imgL = cv2.imread('im1.jpeg', 0)\n",
    "imgR = cv2.imread('im2.jpeg', 0)\n",
    "\n",
    "# Use StereoSGBM to calculate disparity\n",
    "window_size = 5\n",
    "min_disp = 32\n",
    "num_disp = 112-min_disp\n",
    "stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "    numDisparities = num_disp,\n",
    "    blockSize = 16,\n",
    "    P1 = 8*3*window_size**2,\n",
    "    P2 = 32*3*window_size**2,\n",
    "    disp12MaxDiff = 1,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = stereo.compute(imgL,imgR).astype(np.float32) / 16.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       ...,\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = imgL.shape[:2]\n",
    "f = 0.8 * w  # guess for focal length\n",
    "Q = np.float32([[1, 0, 0, -0.5 * w],\n",
    "                    [0, -1, 0, 0.5 * h],  # turn points 180 deg around x-axis,\n",
    "                    [0, 0, 0, -f],  # so that y-axis looks up\n",
    "                    [0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = cv2.reprojectImageTo3D(disparity, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-10.32258  ,   7.7419353, -16.516129 ],\n",
       "        [-10.290322 ,   7.7419353, -16.516129 ],\n",
       "        [-10.258064 ,   7.7419353, -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,   7.7419353, -16.516129 ],\n",
       "        [ 10.258064 ,   7.7419353, -16.516129 ],\n",
       "        [ 10.290322 ,   7.7419353, -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,   7.709677 , -16.516129 ],\n",
       "        [-10.290322 ,   7.709677 , -16.516129 ],\n",
       "        [-10.258064 ,   7.709677 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,   7.709677 , -16.516129 ],\n",
       "        [ 10.258064 ,   7.709677 , -16.516129 ],\n",
       "        [ 10.290322 ,   7.709677 , -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,   7.677419 , -16.516129 ],\n",
       "        [-10.290322 ,   7.677419 , -16.516129 ],\n",
       "        [-10.258064 ,   7.677419 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,   7.677419 , -16.516129 ],\n",
       "        [ 10.258064 ,   7.677419 , -16.516129 ],\n",
       "        [ 10.290322 ,   7.677419 , -16.516129 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-10.32258  ,  -7.645161 , -16.516129 ],\n",
       "        [-10.290322 ,  -7.645161 , -16.516129 ],\n",
       "        [-10.258064 ,  -7.645161 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,  -7.645161 , -16.516129 ],\n",
       "        [ 10.258064 ,  -7.645161 , -16.516129 ],\n",
       "        [ 10.290322 ,  -7.645161 , -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,  -7.677419 , -16.516129 ],\n",
       "        [-10.290322 ,  -7.677419 , -16.516129 ],\n",
       "        [-10.258064 ,  -7.677419 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,  -7.677419 , -16.516129 ],\n",
       "        [ 10.258064 ,  -7.677419 , -16.516129 ],\n",
       "        [ 10.290322 ,  -7.677419 , -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,  -7.709677 , -16.516129 ],\n",
       "        [-10.290322 ,  -7.709677 , -16.516129 ],\n",
       "        [-10.258064 ,  -7.709677 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,  -7.709677 , -16.516129 ],\n",
       "        [ 10.258064 ,  -7.709677 , -16.516129 ],\n",
       "        [ 10.290322 ,  -7.709677 , -16.516129 ]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_img\n",
    "cv2.findChessboardCorners(left_img, (8,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[103, 103, 103],\n",
       "        [103, 103, 103],\n",
       "        [103, 103, 103],\n",
       "        ...,\n",
       "        [ 52,  52,  52],\n",
       "        [ 42,  42,  42],\n",
       "        [ 62,  62,  62]],\n",
       "\n",
       "       [[104, 104, 104],\n",
       "        [103, 103, 103],\n",
       "        [104, 104, 104],\n",
       "        ...,\n",
       "        [ 52,  52,  52],\n",
       "        [ 42,  42,  42],\n",
       "        [ 65,  65,  65]],\n",
       "\n",
       "       [[102, 102, 102],\n",
       "        [101, 101, 101],\n",
       "        [104, 104, 104],\n",
       "        ...,\n",
       "        [ 52,  52,  52],\n",
       "        [ 41,  41,  41],\n",
       "        [ 67,  67,  67]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 43,  43,  43],\n",
       "        [ 45,  45,  45],\n",
       "        [ 46,  46,  46],\n",
       "        ...,\n",
       "        [ 29,  29,  29],\n",
       "        [ 29,  29,  29],\n",
       "        [ 27,  27,  27]],\n",
       "\n",
       "       [[ 45,  45,  45],\n",
       "        [ 45,  45,  45],\n",
       "        [ 51,  51,  51],\n",
       "        ...,\n",
       "        [ 28,  28,  28],\n",
       "        [ 29,  29,  29],\n",
       "        [ 27,  27,  27]],\n",
       "\n",
       "       [[ 46,  46,  46],\n",
       "        [ 48,  48,  48],\n",
       "        [ 55,  55,  55],\n",
       "        ...,\n",
       "        [ 31,  31,  31],\n",
       "        [ 30,  30,  30],\n",
       "        [ 29,  29,  29]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "left = cv2.imread('im1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "cv2.findChessboardCornersSBWithMeta(gray, (6,4), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     18\u001b[0m points_2d_left \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m     19\u001b[0m     (\u001b[39m251\u001b[39m, \u001b[39m379\u001b[39m),\n\u001b[1;32m     20\u001b[0m     (\u001b[39m84\u001b[39m, \u001b[39m352\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     (\u001b[39m411\u001b[39m, \u001b[39m219\u001b[39m),\n\u001b[1;32m     27\u001b[0m ], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Calibrate the camera\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera(world_points, points_2d_left, (\u001b[39m1280\u001b[39;49m, \u001b[39m720\u001b[39;49m), \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# Print the camera matrix\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera Matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define 3D world coordinates of 4 known points\n",
    "world_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32).reshape(1, -1, 3)\n",
    "\n",
    "# Define corresponding 2D image points\n",
    "#407 356 \n",
    "points_2d_left = np.array([\n",
    "    (251, 379),\n",
    "    (84, 352),\n",
    "    (91, 201),\n",
    "    (259, 190),\n",
    "    (407, 356),\n",
    "    (294, 379),\n",
    "    (300, 195),\n",
    "    (411, 219),\n",
    "], dtype=np.float32).reshape(1, -1, 2)\n",
    "\n",
    "# Calibrate the camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(world_points, points_2d_left, (1280, 720), None, None)\n",
    "\n",
    "# Print the camera matrix\n",
    "print(\"Camera Matrix:\")\n",
    "print(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera parameters: \n",
      " [ 1.28673584e+01 -7.08022743e+00  7.63836467e-01  2.65973054e+02\n",
      "  5.08216239e+00  3.26684771e+00 -1.28100314e+01  4.33572277e+02\n",
      "  1.74581898e-02  1.32772732e-02  1.01479734e-03  1.00000000e+00]\n",
      "Mean reprojection error: 0.4362484913196166\n",
      "Camera parameters: \n",
      " [ 1.68842575e+01 -5.62662763e+00  9.04067537e-01  2.71937129e+02\n",
      "  5.45493674e+00  4.64392716e+00 -1.54990563e+01  4.69532176e+02\n",
      "  1.82295906e-02  1.83503713e-02  7.30327158e-04  1.00000000e+00]\n",
      "Mean reprojection error: 0.7810626650427404\n",
      "[[ 1.81027797e-07  4.21788655e-05 -1.18716237e-02]\n",
      " [-4.96572594e-05 -7.02350956e-07  4.55563961e-02]\n",
      " [ 1.39292079e-02 -4.94497562e-02  1.00000000e+00]]\n",
      "the best point (254, 403)\n",
      "3D Reconstruction: [[-13.85506002]\n",
      " [-12.78419918]\n",
      " [ -0.64817932]]\n",
      "the best point (85, 364)\n",
      "3D Reconstruction: [[17.06386603]\n",
      " [ 1.54519934]\n",
      " [ 1.11012526]]\n",
      "the best point (98, 196)\n",
      "3D Reconstruction: [[54.47631393]\n",
      " [52.48770536]\n",
      " [ 2.28063004]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 253\u001b[0m\n\u001b[1;32m    250\u001b[0m cv2\u001b[39m.\u001b[39msetMouseCallback(\u001b[39m'\u001b[39m\u001b[39mImage1\u001b[39m\u001b[39m'\u001b[39m, click_and_mark)\n\u001b[1;32m    252\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     key \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# Press 'q' to quit and save the points\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('im1_points.txt', 'r') as f:\n",
    "    points1 = f.readlines()\n",
    "\n",
    "with open('im2_points.txt', 'r') as f:\n",
    "    points2 = f.readlines()\n",
    "\n",
    "with open('3DCoordinates.txt', 'r') as f:\n",
    "    points_3d = f.readlines()\n",
    "\n",
    "points1 = [point.split() for point in points1]  # 2D image points\n",
    "points2 = [point.split() for point in points2]  # 2D image points\n",
    "points_3d = [point.split() for point in points_3d]  # 3D world points\n",
    "im1 = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "im2 = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "def camera_calibration(image_points, world_points):\n",
    "    A = np.zeros((len(image_points) * 2, 12))\n",
    "    for i, (image, object) in enumerate(zip(image_points, world_points)):\n",
    "        X, Y, Z = [float(point) for point in object]\n",
    "        x, y = [float(point) for point in image]\n",
    "        A[2 * i, :] = [-X, -Y, -Z, -1, 0, 0, 0, 0, x * X, x * Y, x * Z, x]\n",
    "        A[2 * i + 1, :] = [0, 0, 0, 0, -X, -Y, -Z, -1, y * X, y * Y, y * Z, y]\n",
    "    # Perform SVD decomposition\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    P = V[-1].reshape((3, 4))\n",
    "\n",
    "    # Extract camera parameters from V\n",
    "    camera_params = V[-1, :12]\n",
    "    camera_params /= camera_params[-1]  # Normalize the parameters\n",
    "\n",
    "    print(f'Camera parameters: \\n {camera_params}')\n",
    "    # Compute the calibration error\n",
    "    projection_error = 0.0\n",
    "    for i, (image, object) in enumerate(zip(image_points, world_points)):\n",
    "        X = [float(point) for point in object]\n",
    "        X.append(1)\n",
    "        x = [float(point) for point in image]\n",
    "        x.append(1)\n",
    "\n",
    "        projected_x = np.dot(camera_params.reshape((3, 4)), X)\n",
    "        projected_x /= projected_x[-1]  # Normalizing\n",
    "        projection_error += np.linalg.norm(projected_x[:-1] - x[:-1])\n",
    "\n",
    "    mean_error = projection_error / len(image_points)\n",
    "    print(\"Mean reprojection error: {}\".format(mean_error))\n",
    "\n",
    "    return camera_params\n",
    "\n",
    "\n",
    "def calculate_fundamental_matrix(img1, img2):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors for both images\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Initialize Brute-Force Matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Apply ratio test to keep good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extract corresponding keypoints\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Compute fundamental matrix using RANSAC\n",
    "    fundamental_matrix, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC)\n",
    "\n",
    "    print(fundamental_matrix)\n",
    "    return fundamental_matrix\n",
    "\n",
    "\n",
    "def calculate_zncc(img1, img2, point1, point2, window_size):\n",
    "    \"\"\"\n",
    "    Calculate Zero Mean Normalized Cross-Correlation (ZNCC) between two pixel points.\n",
    "\n",
    "    Args:\n",
    "        img1 (numpy.ndarray): The first image.\n",
    "        img2 (numpy.ndarray): The second image.\n",
    "        point1 (tuple): Coordinates (row, col) of the first point in img1.\n",
    "        point2 (tuple): Coordinates (row, col) of the corresponding point in img2.\n",
    "        window_size (int): Size of the window around the points for ZNCC calculation.\n",
    "\n",
    "    Returns:\n",
    "        zncc_score (float): ZNCC score between the patches centered at the two points.\n",
    "    \"\"\"\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    # Extract patches around the points\n",
    "    patch1 = img1[point1[0] - half_window:point1[0] + half_window + 1,\n",
    "             point1[1] - half_window:point1[1] + half_window + 1]\n",
    "\n",
    "    patch2 = img2[point2[0] - half_window:point2[0] + half_window + 1,\n",
    "             point2[1] - half_window:point2[1] + half_window + 1]\n",
    "\n",
    "    # Calculate means of the patches\n",
    "    mean1 = np.mean(patch1)\n",
    "    mean2 = np.mean(patch2)\n",
    "\n",
    "    # Calculate zero-mean patches\n",
    "    zero_mean_patch1 = patch1 - mean1\n",
    "    zero_mean_patch2 = patch2 - mean2\n",
    "\n",
    "    # Calculate the cross-correlation\n",
    "    cross_corr = np.sum(zero_mean_patch1 * zero_mean_patch2)\n",
    "\n",
    "    # Calculate the standard deviations\n",
    "    std_dev1 = np.sqrt(np.sum(zero_mean_patch1 ** 2))\n",
    "    std_dev2 = np.sqrt(np.sum(zero_mean_patch2 ** 2))\n",
    "\n",
    "    # Calculate ZNCC\n",
    "    zncc_score = cross_corr / (std_dev1 * std_dev2)\n",
    "\n",
    "    return zncc_score\n",
    "\n",
    "\n",
    "def drawEpipolarLine(u, v, F, img1, img2):\n",
    "\n",
    "    p = np.array([[u, v, 1]], dtype=np.float32)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints\n",
    "    keypoints1, desc1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, desc2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Create a Brute-Force Matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "    # Match descriptors from both images\n",
    "    matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "    # Apply ratio test to filter good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.3 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    src_pts = np.float32([keypoints1[match.queryIdx].pt for match in good_matches])\n",
    "    dst_pts = np.float32([keypoints2[match.trainIdx].pt for match in good_matches])\n",
    "\n",
    "    distance_from_keypoints = list()\n",
    "    for i, pt in enumerate(src_pts):\n",
    "        distance_from_keypoints.append((math.sqrt((pt[0] - u)**2 + (pt[1] - v)**2), pt, dst_pts[i]))\n",
    "    distance_from_keypoints.sort(key=lambda x: x[0])\n",
    "    distance_from_keypoints = distance_from_keypoints[0]\n",
    "\n",
    "    disparity = distance_from_keypoints[1][0] - distance_from_keypoints[2][0]\n",
    "\n",
    "    line = cv2.computeCorrespondEpilines(p, 1, F)\n",
    "    epipolar_line = line.reshape(-1, 3)\n",
    "    # Calculate epipolar line parameters\n",
    "    epipolar_line = epipolar_line.flatten()\n",
    "    a, b, c = epipolar_line\n",
    "\n",
    "    # Calculate the range of x coordinates for drawing the line\n",
    "    img1_height, img1_width = img1.shape[:2]\n",
    "    x1 = 0\n",
    "    y1 = int(-c / b)\n",
    "    x2 = img1_width - 1\n",
    "    y2 = int(-(a * x2 + c) / b)\n",
    "\n",
    "    img_with_line = cv2.line(img2, [x1, y1], [x2, y2], (0, 255, 0))\n",
    "\n",
    "    points_right = list()\n",
    "    ranges = [int(u-disparity), int(u+disparity)]\n",
    "    for x in range(min(ranges), max(ranges)):\n",
    "        y = int(-(epipolar_line[0] * x + epipolar_line[2]) / epipolar_line[1])\n",
    "\n",
    "        try:\n",
    "            zncc_score = calculate_zncc(img1, img2, (u, v), (x, y), window_size=7)\n",
    "            points_right.append(((x, y), zncc_score))\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    points_right.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_point_right = points_right[0]\n",
    "\n",
    "    cv2.circle(img_with_line, (best_point_right[0][0], best_point_right[0][1]), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow('Image', img_with_line)\n",
    "    cv2.waitKey(0)\n",
    "    print(f'the best point {best_point_right[0]}')\n",
    "    return best_point_right[0]\n",
    "\n",
    "\n",
    "def three_dimensional_reconstruction(camera_matrix1, camera_matrix2, p1, p2):\n",
    "    A = np.zeros((4, 3))\n",
    "\n",
    "    A[0][0] = p1[0] * camera_matrix1[8] - camera_matrix1[0]\n",
    "    A[0][1] = p1[0] * camera_matrix1[9] - camera_matrix1[1]\n",
    "    A[0][2] = p1[0] * camera_matrix1[10] - camera_matrix1[2]\n",
    "\n",
    "    A[1][0] = p1[1] * camera_matrix1[8] - camera_matrix1[4]\n",
    "    A[1][1] = p1[1] * camera_matrix1[9] - camera_matrix1[5]\n",
    "    A[1][2] = p1[1] * camera_matrix1[10] - camera_matrix1[6]\n",
    "\n",
    "    A[2][0] = p2[0] * camera_matrix2[8] - camera_matrix2[1]\n",
    "    A[2][1] = p2[0] * camera_matrix2[9] - camera_matrix2[2]\n",
    "    A[2][2] = p2[0] * camera_matrix2[10] - camera_matrix2[3]\n",
    "\n",
    "    A[3][0] = p2[0] * camera_matrix2[8] - camera_matrix2[4]\n",
    "    A[3][1] = p2[0] * camera_matrix2[9] - camera_matrix2[5]\n",
    "    A[3][2] = p2[0] * camera_matrix2[10] - camera_matrix2[6]\n",
    "\n",
    "    d = np.zeros((1, 4))\n",
    "    d[0][0] = p1[0] * camera_matrix1[11] - camera_matrix1[3]\n",
    "    d[0][1] = p1[1] * camera_matrix1[11] - camera_matrix1[7]\n",
    "    d[0][2] = p2[0] * camera_matrix2[11] - camera_matrix2[3]\n",
    "    d[0][3] = p2[1] * camera_matrix2[11] - camera_matrix2[7]\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    # Calculate the pseudoinverse of S\n",
    "    S_pseudo = np.zeros(A.shape).T\n",
    "    S_pseudo[:S.shape[0], :S.shape[0]] = np.diag(1 / S)\n",
    "    # Calculate the pseudoinverse of A using SVD\n",
    "    A_pseudo = np.dot(np.dot(Vt.T, S_pseudo), U.T)\n",
    "\n",
    "    # Solve for matrix X\n",
    "    X = np.dot(A_pseudo, d.T)\n",
    "\n",
    "    return X\n",
    "\n",
    "M1 = camera_calibration(points1, points_3d)\n",
    "M2 = camera_calibration(points2, points_3d)\n",
    "F = calculate_fundamental_matrix(im1, im2)\n",
    "\n",
    "def click_and_mark(event, x, y, flags, param):\n",
    "    global points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        #points = (x, y)\n",
    "        cv2.circle(im1, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Image1', im1)# Mark the clicked point with a red circle\n",
    "\n",
    "        p_ = drawEpipolarLine(x, y, F, im1, im2)\n",
    "        print('3D Reconstruction: {}'.format(three_dimensional_reconstruction(M1, M2, (x, y), p_)))\n",
    "\n",
    "\n",
    "cv2.imshow('Image1', im1)\n",
    "cv2.setMouseCallback('Image1', click_and_mark)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # Press 'q' to quit and save the points\n",
    "    if key == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m points_2d_left\n\u001b[0;32m----> 6\u001b[0m ret, M1, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera(world_points, points_2d_left, img1\u001b[39m.\u001b[39mshape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m ret, M2, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera(world_points, points_2d_right, img2\u001b[39m.\u001b[39mshape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img1' is not defined"
     ]
    }
   ],
   "source": [
    "points_2d_left\n",
    "img1 = cv2.imread('im1.jpeg')\n",
    "im2 = cv2.imread('im2.jpeg')\n",
    "\n",
    "ret, M1, dist, rvecs, tvecs = cv2.calibrateCamera(world_points, points_2d_left, img1.shape[::-1], None, None)\n",
    "ret, M2, dist, rvecs, tvecs = cv2.calibrateCamera(world_points, points_2d_right, img2.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('im1.jpeg', 0)\n",
    "img2 = cv2.imread('im2.jpeg', 0)\n",
    "\n",
    "keypoints1, descriptors1 = cv2.SIFT_create().detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = cv2.SIFT_create().detectAndCompute(img2, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "points1 = np.float32([keypoints1[match.queryIdx].pt for match in matches]).reshape(-1, 1, 2)\n",
    "points2 = np.float32([keypoints2[match.trainIdx].pt for match in matches]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, mask = cv2.findFundamentalMat(points1, points2, cv2.FM_LMEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.17689581e-07,  4.56200225e-05, -1.22266601e-02],\n",
       "       [-5.26303938e-05, -1.20936307e-06,  4.61642610e-02],\n",
       "       [ 1.39577009e-02, -4.98693661e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = points1[mask.ravel() == 1]\n",
    "pts2 = points2[mask.ravel() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img1.shape[:2]\n",
    "_, h_1, h_2 = cv2.stereoRectifyUncalibrated(pts1, pts2, F, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_l_rect = cv2.warpPerspective(img1, h_1, (width, height))\n",
    "img_r_rect = cv2.warpPerspective(img2, h_2, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgbm_disparity_compute(img_l, img_r, win_size, block_size, ratio, disp_max_diff, sp_range):\n",
    "\n",
    "    window_size = 3\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(minDisparity=16,\n",
    "                                        numDisparities=96,\n",
    "                                        blockSize=block_size,\n",
    "                                        P1=8*3*window_size**2,\n",
    "                                        P2=32*3*window_size**2,\n",
    "                                        disp12MaxDiff=disp_max_diff,\n",
    "                                        uniquenessRatio=ratio,\n",
    "                                        speckleWindowSize=win_size,\n",
    "                                        speckleRange=sp_range,\n",
    "                                        preFilterCap=63,\n",
    "                                        mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "    # FILTER Parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.2\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "\n",
    "    displ = left_matcher.compute(img_l, img_r)  \n",
    "    dispr = right_matcher.compute(img_r, img_l)\n",
    "    displ = np.int16(displ)\n",
    "    dispr = np.int16(dispr)\n",
    "    filtered_img = wls_filter.filter(displ, img_l, None, dispr)\n",
    "\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = sgbm_disparity_compute(img_l_rect, img_r_rect, 400, 7,\n",
    "                                       12, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16, -16, -16, ..., 618, 618, 618],\n",
       "       [-16, -16, -16, ..., 618, 618, 618],\n",
       "       [-16, -16, -16, ..., 618, 618, 618],\n",
       "       ...,\n",
       "       [-16, -16, -16, ..., 395, 395, 395],\n",
       "       [-16, -16, -16, ..., 395, 395, 395],\n",
       "       [-16, -16, -16, ..., 395, 395, 395]], dtype=int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 150, 150, 150],\n",
       "       [  0,   0,   0, ..., 149, 149, 149],\n",
       "       [  0,   0,   0, ..., 149, 149, 149],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 170, 171, 171],\n",
       "       [  0,   0,   0, ..., 170, 171, 171],\n",
       "       [  0,   0,   0, ..., 170, 170, 171]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_l_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.16261867e-02, -2.21409654e-05,  5.56005211e+00],\n",
       "       [-2.03405499e-02,  5.05663459e-02,  4.37605670e+00],\n",
       "       [-7.63130353e-05, -4.27515690e-06,  6.76026059e-02]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc55c2139a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_calib_file(fn, height, width):\n",
    "    ''' Read the calibration file \n",
    "        and return the projection matrix Q'''\n",
    "    # open file\n",
    "    file = open(fn, 'r')\n",
    "    # read focal length\n",
    "    focal_length = np.float32(file.readline()[6: 14: 1])\n",
    "    # read the baseline\n",
    "    baseline = np.float32(file.readlines()[2].partition('=')[2].rstrip('\\n'))\n",
    "    Q = np.float32([\n",
    "                    [1,  0,  0, -0.5 * width],\n",
    "                    [0, -1,  0, 0.5 * height],\n",
    "                    [0,  0,  0, -focal_length],\n",
    "                    [0,  0, -1 / baseline, 0]\n",
    "                   ])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = read_calib_file(calib, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0 1.5 3.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcalib.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39m# read focal length\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m focal_length \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfloat32(file\u001b[39m.\u001b[39;49mreadline()[\u001b[39m6\u001b[39;49m: \u001b[39m14\u001b[39;49m: \u001b[39m1\u001b[39;49m])\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '0 1.5 3.'"
     ]
    }
   ],
   "source": [
    "file = open('calib.txt', 'r')\n",
    "# read focal length\n",
    "focal_length = np.float32(file.readline()[6: 14: 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cam0=[4844.97 0 1332.834; 0 4844.97 979.162; 0 0 1]\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('calib.txt', 'r')\n",
    "file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('im1_points.txt', 'r') as f:\n",
    "    points1 = f.readlines()\n",
    "\n",
    "with open('im2_points.txt', 'r') as f:\n",
    "    points2 = f.readlines()\n",
    "\n",
    "with open('3DCoordinates.txt', 'r') as f:\n",
    "    points_3d = f.readlines()\n",
    "\n",
    "points1 = [point.split() for point in points1]  # 2D image points\n",
    "points2 = [point.split() for point in points2]  # 2D image points\n",
    "points_3d = [point.split() for point in points_3d]  # 3D world points\n",
    "im1 = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "im2 = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = np.array(points_3d, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1.5,  3.8],\n",
       "       [ 0. , 22.5,  3.8],\n",
       "       [ 0. , 22.5, 18.8],\n",
       "       [ 0. ,  1.5, 18.8],\n",
       "       [24.3,  0. ,  3.8],\n",
       "       [ 3.3,  0. ,  3.8],\n",
       "       [ 3.3,  0. , 18.8],\n",
       "       [24.3,  0. , 18.8]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "points1 = np.array(points1, dtype=np.float32)\n",
    "points2 = np.array(points2, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3408: error: (-210:Unsupported format or combination of formats) objectPoints should contain vector of vectors of points of type Point3f in function 'collectCalibrationData'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ret, mtx1, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera(points_3d, points1, im1\u001b[39m.\u001b[39;49mshape[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3408: error: (-210:Unsupported format or combination of formats) objectPoints should contain vector of vectors of points of type Point3f in function 'collectCalibrationData'\n"
     ]
    }
   ],
   "source": [
    "ret, mtx1, dist, rvecs, tvecs = cv2.calibrateCamera(points_3d, points1, im1.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:1575: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m criteria \u001b[39m=\u001b[39m (cv2\u001b[39m.\u001b[39mTERM_CRITERIA_EPS \u001b[39m+\u001b[39m cv2\u001b[39m.\u001b[39mTERM_CRITERIA_MAX_ITER, \u001b[39m30\u001b[39m, \u001b[39m0.001\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# Calibrate camera\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([object_points], [image_points], gray_image\u001b[39m.\u001b[39;49mshape[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(mtx)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:1575: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Load one of the stereo images (assuming you have both images)\n",
    "image = cv2.imread(\"im1.jpeg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Set calibration criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Calibrate camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera([object_points], [image_points], gray_image.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix:\")\n",
    "print(mtx)\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:1575: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m initial_camera_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m500\u001b[39m, \u001b[39m0\u001b[39m, gray_image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m],\n\u001b[1;32m     37\u001b[0m                                   [\u001b[39m0\u001b[39m, \u001b[39m500\u001b[39m, gray_image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m],\n\u001b[1;32m     38\u001b[0m                                   [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Calibrate camera\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([object_points], [image_points], gray_image\u001b[39m.\u001b[39;49mshape[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], initial_camera_matrix, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(mtx)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:1575: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Load one of the stereo images (assuming you have both images)\n",
    "image = cv2.imread(\"im1.jpeg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Set calibration criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Initial guess for the camera matrix\n",
    "initial_camera_matrix = np.array([[500, 0, gray_image.shape[1] / 2],\n",
    "                                  [0, 500, gray_image.shape[0] / 2],\n",
    "                                  [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Calibrate camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera([object_points], [image_points], gray_image.shape[::-1], initial_camera_matrix, None)\n",
    "\n",
    "print(\"Camera matrix:\")\n",
    "print(mtx)\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3500: error: (-5:Bad argument) CALIB_USE_INTRINSIC_GUESS flag is set, but the camera matrix is not 3x3 in function 'prepareCameraMatrix'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m initial_camera_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m500\u001b[39m, \u001b[39m0\u001b[39m, gray_image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m],\n\u001b[1;32m     37\u001b[0m                                   [\u001b[39m0\u001b[39m, \u001b[39m500\u001b[39m, gray_image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m],\n\u001b[1;32m     38\u001b[0m                                   [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Calibrate camera\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([object_points], [image_points], gray_image\u001b[39m.\u001b[39;49mshape[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, flags\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mCALIB_USE_INTRINSIC_GUESS)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(mtx)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3500: error: (-5:Bad argument) CALIB_USE_INTRINSIC_GUESS flag is set, but the camera matrix is not 3x3 in function 'prepareCameraMatrix'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Load one of the stereo images (assuming you have both images)\n",
    "image = cv2.imread(\"im1.jpeg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Set calibration criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Initial guess for the camera matrix\n",
    "initial_camera_matrix = np.array([[500, 0, gray_image.shape[1] / 2],\n",
    "                                  [0, 500, gray_image.shape[0] / 2],\n",
    "                                  [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Calibrate camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera([object_points], [image_points], gray_image.shape[::-1], None, None, flags=cv2.CALIB_USE_INTRINSIC_GUESS)\n",
    "\n",
    "print(\"Camera matrix:\")\n",
    "print(mtx)\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix:\n",
      "[[500.   0. 320.]\n",
      " [  0. 500. 240.]\n",
      " [  0.   0.   1.]]\n",
      "\n",
      "Distortion coefficients:\n",
      "[[-0.83380244]\n",
      " [ 0.45170045]\n",
      " [ 0.10547262]\n",
      " [-0.00704663]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "image = cv2.imread(\"im1.jpeg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create initial camera matrix\n",
    "camera_matrix = np.array([[500, 0, gray_image.shape[1] / 2],\n",
    "                                 [0, 500, gray_image.shape[0] / 2],\n",
    "                                 [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Distortion coefficients (assuming no distortion)\n",
    "distortion_coeffs = np.zeros((5, 1), dtype=np.float32)\n",
    "\n",
    "# Calibrate camera\n",
    "ret, mtx1, distortion_coeffs, rvecs, tvecs = cv2.calibrateCamera([object_points], [image_points], (gray_image.shape[1], gray_image.shape[0]), camera_matrix, distortion_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_K3)\n",
    "ret, mtx2, distortion_coeffs, rvecs, tvecs = cv2.calibrateCamera([object_points], [image_points], (gray_image.shape[1], gray_image.shape[0]), camera_matrix, distortion_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_K3)\n",
    "\n",
    "print(\"Camera matrix:\")\n",
    "print(mtx1)\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(distortion_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3397: error: (-2:Unspecified error) in function 'void cv::collectCalibrationData(cv::InputArrayOfArrays, cv::InputArrayOfArrays, cv::InputArrayOfArrays, int, cv::Mat&, cv::Mat&, cv::Mat*, cv::Mat&)'\n>  (expected: 'nimages == (int)imagePoints1.total()'), where\n>     'nimages' is 1\n> must be equal to\n>     '(int)imagePoints1.total()' is 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 57\u001b[0m\n\u001b[1;32m     47\u001b[0m distortion_coeffs_guess \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     49\u001b[0m \u001b[39m# Calibrate stereo cameras\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m# ret, camera_matrix1, distortion_coeffs1, camera_matrix2, distortion_coeffs2, R, T, E, F = cv2.stereoCalibrate(\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m#     [object_points], [image_points1], [image_points2],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m#     gray_image.shape[::-1], flags=cv2.CALIB_FIX_INTRINSIC\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m ret1, mtx1, dist1, rvecs1, tvecs1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([object_points], image_points1, gray_image\u001b[39m.\u001b[39;49mshape[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], camera_matrix1_guess, distortion_coeffs_guess, flags\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mCALIB_FIX_INTRINSIC)\n\u001b[1;32m     58\u001b[0m ret2, mtx2, dist2, rvecs2, tvecs2 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([object_points], image_points2, gray_image\u001b[39m.\u001b[39mshape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], camera_matrix2_guess, distortion_coeffs_guess, flags\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mCALIB_FIX_INTRINSIC)\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera matrix 1:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:3397: error: (-2:Unspecified error) in function 'void cv::collectCalibrationData(cv::InputArrayOfArrays, cv::InputArrayOfArrays, cv::InputArrayOfArrays, int, cv::Mat&, cv::Mat&, cv::Mat*, cv::Mat&)'\n>  (expected: 'nimages == (int)imagePoints1.total()'), where\n>     'nimages' is 1\n> must be equal to\n>     '(int)imagePoints1.total()' is 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 1st image points\n",
    "image_points1 = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 2nd image points\n",
    "image_points2 = np.array([\n",
    "    [258, 405],\n",
    "    [105, 364],\n",
    "    [114, 198],\n",
    "    [268, 178],\n",
    "    [474, 376],\n",
    "    [313, 403],\n",
    "    [322, 183],\n",
    "    [480, 213]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Define camera intrinsic matrices (initial guess for both cameras)\n",
    "camera_matrix1_guess = np.array([[500, 0, gray_image.shape[1] / 2],\n",
    "                                 [0, 500, gray_image.shape[0] / 2],\n",
    "                                 [0, 0, 1]], dtype=np.float32)\n",
    "camera_matrix2_guess = camera_matrix1_guess.copy()\n",
    "\n",
    "# Define distortion coefficients (initial guess for both cameras)\n",
    "distortion_coeffs_guess = np.zeros((4, 1), dtype=np.float32)\n",
    "\n",
    "# Calibrate stereo cameras\n",
    "# ret, camera_matrix1, distortion_coeffs1, camera_matrix2, distortion_coeffs2, R, T, E, F = cv2.stereoCalibrate(\n",
    "#     [object_points], [image_points1], [image_points2],\n",
    "#     camera_matrix1_guess, distortion_coeffs_guess,\n",
    "#     camera_matrix2_guess, distortion_coeffs_guess,\n",
    "#     gray_image.shape[::-1], flags=cv2.CALIB_FIX_INTRINSIC\n",
    "# )\n",
    "\n",
    "ret1, mtx1, dist1, rvecs1, tvecs1 = cv2.calibrateCamera([object_points], image_points1, gray_image.shape[::-1], camera_matrix1_guess, distortion_coeffs_guess, flags=cv2.CALIB_FIX_INTRINSIC)\n",
    "ret2, mtx2, dist2, rvecs2, tvecs2 = cv2.calibrateCamera([object_points], image_points2, gray_image.shape[::-1], camera_matrix2_guess, distortion_coeffs_guess, flags=cv2.CALIB_FIX_INTRINSIC)\n",
    "\n",
    "\n",
    "print(\"Camera matrix 1:\")\n",
    "print(mtx1)\n",
    "print(\"\\nDistortion coefficients 1:\")\n",
    "print(dist1)\n",
    "\n",
    "print(\"\\nCamera matrix 2:\")\n",
    "print(mtx2)\n",
    "print(\"\\nDistortion coefficients 2:\")\n",
    "print(dist2)\n",
    "\n",
    "print(\"\\nRotation matrix 1:\")\n",
    "print(rvecs1)\n",
    "print(\"\\nRotation matrix 2:\")\n",
    "print(rvecs2)\n",
    "print(\"\\nTranslation matrix 1:\")\n",
    "print(tvecs1)\n",
    "print(\"\\nTranslation matrix 2:\")\n",
    "print(tvecs2)\n",
    "# print(\"\\nEssential matrix:\")\n",
    "# print(E)\n",
    "# print(\"\\nFundamental matrix:\")\n",
    "# print(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.614406819399291"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix 1:\n",
      "[[650.44696635   0.         281.64483807]\n",
      " [  0.         636.26293457 205.84729924]\n",
      " [  0.           0.           1.        ]]\n",
      "Camera matrix 2:\n",
      "[[709.8899907    0.         306.12094705]\n",
      " [  0.         657.65720807  69.98342609]\n",
      " [  0.           0.           1.        ]]\n",
      "\n",
      "Distortion coefficients:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "3D Coordinates (X, Y, Z):\n",
      "-9.38532 -5.1391873 -1.3808758\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "image_points2 = np.array([\n",
    "    [258, 405],\n",
    "    [105, 364],\n",
    "    [114, 198],\n",
    "    [268, 178],\n",
    "    [474, 376],\n",
    "    [313, 403],\n",
    "    [322, 183],\n",
    "    [480, 213]\n",
    "], dtype=np.float32)\n",
    "\n",
    "image = cv2.imread(\"im1.jpeg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create initial camera matrix\n",
    "camera_matrix = np.array([[500, 0, gray_image.shape[1] / 2],\n",
    "                                 [0, 500, gray_image.shape[0] / 2],\n",
    "                                 [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Distortion coefficients (assuming no distortion)\n",
    "distortion_coeffs = np.zeros((5, 1), dtype=np.float32)\n",
    "\n",
    "# Calibrate camera\n",
    "ret1, mtx1, distortion_coeffs1, R1, T1 = cv2.calibrateCamera([object_points], [image_points], (gray_image.shape[1], gray_image.shape[0]), camera_matrix, distortion_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_K3)\n",
    "ret2, mtx2, distortion_coeffs2, R2, T2 = cv2.calibrateCamera([object_points], [image_points2], (gray_image.shape[1], gray_image.shape[0]), camera_matrix, distortion_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_K3)\n",
    "\n",
    "print(\"Camera matrix 1:\")\n",
    "print(mtx1)\n",
    "print(\"Camera matrix 2:\")\n",
    "print(mtx2)\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(distortion_coeffs)\n",
    "\n",
    "R1_t = cv2.Rodrigues(T1[0])[0]\n",
    "T1_t = T1[0]\n",
    "Rt_1 = np.concatenate([R1_t,T1_t], axis=-1) # [R|t]\n",
    "P1 = np.matmul(mtx1,Rt_1) # A[R|t]\n",
    "\n",
    "R2_t = cv2.Rodrigues(T2[0])[0]\n",
    "T2_t = T2[0]\n",
    "Rt_2 = np.concatenate([R2_t,T2_t], axis=-1) # [R|t]\n",
    "P2 = np.matmul(mtx2,Rt_2) # A[R|t]\n",
    "\n",
    "img1 = cv2.imread('im1.jpeg', 0)\n",
    "img2 = cv2.imread('im2.jpeg', 0)\n",
    "\n",
    "\n",
    "keypoints1, descriptors1 = cv2.SIFT_create().detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = cv2.SIFT_create().detectAndCompute(img2, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "points1 = np.float32([keypoints1[match.queryIdx].pt for match in matches])\n",
    "points2 = np.float32([keypoints2[match.trainIdx].pt for match in matches])\n",
    "\n",
    "# Perform triangulation\n",
    "points_3d_homogeneous = cv2.triangulatePoints(P1, P2, np.array([256, 451]), np.array([256, 451]))\n",
    "\n",
    "# Convert homogeneous coordinates to 3D Cartesian coordinates\n",
    "points_3d_cartesian = cv2.convertPointsFromHomogeneous(points_3d_homogeneous.T)\n",
    "\n",
    "# Extract the 3D coordinates\n",
    "x_3d = points_3d_cartesian[0, 0, 0]\n",
    "y_3d = points_3d_cartesian[0, 0, 1]\n",
    "z_3d = points_3d_cartesian[0, 0, 2]\n",
    "6\n",
    "print(\"3D Coordinates (X, Y, Z):\")\n",
    "print(x_3d, y_3d, z_3d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret1, mtx1, distortion_coeffs1, R1, T1 = cv2.calibrateCamera([object_points], [image_points], (gray_image.shape[1], gray_image.shape[0]), camera_matrix, distortion_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_K3)\n",
    "ret2, mtx2, distortion_coeffs2, R2, T2 = cv2.calibrateCamera([object_points], [image_points2], (gray_image.shape[1], gray_image.shape[0]), camera_matrix, distortion_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_K3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 1)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(mtx1.shape), \n",
    "print(R1[0].shape)\n",
    "print(T1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1_t = cv2.Rodrigues(T1[0])[0]\n",
    "T1_t = T1[0]\n",
    "Rt = np.concatenate([R1_t,T1_t], axis=-1) # [R|t]\n",
    "P = np.matmul(mtx1,Rt) # A[R|t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,3) and (1,6,1) not aligned: 3 (dim 1) != 6 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m proj_matrix1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(mtx1, np\u001b[39m.\u001b[39;49mhstack((R1, T1)))\n\u001b[1;32m      2\u001b[0m proj_matrix2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(mtx1, np\u001b[39m.\u001b[39mhstack((R2, T2)))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,3) and (1,6,1) not aligned: 3 (dim 1) != 6 (dim 1)"
     ]
    }
   ],
   "source": [
    "proj_matrix1 = np.dot(mtx1, np.hstack((R1, T1)))\n",
    "proj_matrix2 = np.dot(mtx1, np.hstack((R2, T2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:1575: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m distortion_coeffs_guess \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Calibrate camera\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m ret, camera_matrix, distortion_coeffs, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([object_points], [image_points], gray_image\u001b[39m.\u001b[39;49mshape[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], camera_matrix_guess, distortion_coeffs_guess)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(camera_matrix)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/calib3d/src/calibration.cpp:1575: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Load one of the stereo images (assuming you have both images)\n",
    "image = cv2.imread(\"im1.jpeg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define camera intrinsic matrix (initial guess)\n",
    "camera_matrix_guess = np.array([[500, 0, gray_image.shape[1] / 2],\n",
    "                                 [0, 500, gray_image.shape[0] / 2],\n",
    "                                 [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Define distortion coefficients (initial guess)\n",
    "distortion_coeffs_guess = np.zeros((4, 1), dtype=np.float32)\n",
    "\n",
    "# Calibrate camera\n",
    "ret, camera_matrix, distortion_coeffs, rvecs, tvecs = cv2.calibrateCamera([object_points], [image_points], gray_image.shape[::-1], camera_matrix_guess, distortion_coeffs_guess)\n",
    "\n",
    "print(\"Camera matrix:\")\n",
    "print(camera_matrix)\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(distortion_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((R1, T1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as N\n",
    "def DLTrecon(nd, nc, Ls, uvs):\n",
    "    '''\n",
    "    Reconstruction of object point from image point(s) based on the DLT parameters.\n",
    "\n",
    "    This code performs 2D or 3D DLT point reconstruction with any number of views (cameras).\n",
    "    For 3D DLT, at least two views (cameras) are necessary.\n",
    "    Inputs:\n",
    "     nd is the number of dimensions of the object space: 3 for 3D DLT and 2 for 2D DLT.\n",
    "     nc is the number of cameras (views) used.\n",
    "     Ls (array type) are the camera calibration parameters of each camera \n",
    "      (is the output of DLTcalib function). The Ls parameters are given as columns\n",
    "      and the Ls for different cameras as rows.\n",
    "     uvs are the coordinates of the point in the image 2D space of each camera.\n",
    "      The coordinates of the point are given as columns and the different views as rows.\n",
    "    Outputs:\n",
    "     xyz: point coordinates in space\n",
    "    '''\n",
    "    \n",
    "    #Convert Ls to array:\n",
    "    Ls = N.asarray(Ls) \n",
    "    #Check the parameters:\n",
    "    if Ls.ndim ==1 and nc != 1:\n",
    "        raise ValueError('Number of views (%d) and number of sets of camera calibration parameters (1) are different.' %(nc))    \n",
    "    if Ls.ndim > 1 and nc != Ls.shape[0]:\n",
    "        raise ValueError('Number of views (%d) and number of sets of camera calibration parameters (%d) are different.' %(nc, Ls.shape[0]))\n",
    "    if nd == 3 and Ls.ndim == 1:\n",
    "        raise ValueError('At least two sets of camera calibration parameters are needed for 3D point reconstruction.')\n",
    "\n",
    "    if nc == 1: #2D and 1 camera (view), the simplest (and fastest) case\n",
    "        #One could calculate inv(H) and input that to the code to speed up things if needed.\n",
    "        #(If there is only 1 camera, this transformation is all Floatcanvas2 might need)\n",
    "        Hinv = N.linalg.inv( Ls.reshape(3,3) )\n",
    "        #Point coordinates in space:\n",
    "        xyz = N.dot( Hinv,[uvs[0],uvs[1],1] ) \n",
    "        xyz = xyz[0:2]/xyz[2]       \n",
    "    else:\n",
    "        M = []\n",
    "        for i in range(nc):\n",
    "            L = Ls[i,:]\n",
    "            u,v = uvs[i][0], uvs[i][1] #this indexing works for both list and numpy array\n",
    "            if nd == 2:      \n",
    "                M.append( [L[0]-u*L[6], L[1]-u*L[7], L[2]-u*L[8]] )\n",
    "                M.append( [L[3]-v*L[6], L[4]-v*L[7], L[5]-v*L[8]] )\n",
    "            elif nd == 3:  \n",
    "                M.append( [L[0]-u*L[8], L[1]-u*L[9], L[2]-u*L[10], L[3]-u*L[11]] )\n",
    "                M.append( [L[4]-v*L[8], L[5]-v*L[9], L[6]-v*L[10], L[7]-v*L[11]] )\n",
    "        \n",
    "        #Find the xyz coordinates:\n",
    "        U, S, Vh = N.linalg.svd(N.asarray(M))\n",
    "        #Point coordinates in space:\n",
    "        xyz = Vh[-1,0:-1] / Vh[-1,-1]\n",
    "    \n",
    "    return xyz\n",
    "\n",
    "\n",
    "\n",
    "def DLTcalib(nd, xyz, uv):\n",
    "    '''\n",
    "    Camera calibration by DLT using known object points and their image points.\n",
    "\n",
    "    This code performs 2D or 3D DLT camera calibration with any number of views (cameras).\n",
    "    For 3D DLT, at least two views (cameras) are necessary.\n",
    "    Inputs:\n",
    "     nd is the number of dimensions of the object space: 3 for 3D DLT and 2 for 2D DLT.\n",
    "     xyz are the coordinates in the object 3D or 2D space of the calibration points.\n",
    "     uv are the coordinates in the image 2D space of these calibration points.\n",
    "     The coordinates (x,y,z and u,v) are given as columns and the different points as rows.\n",
    "     For the 2D DLT (object planar space), only the first 2 columns (x and y) are used.\n",
    "     There must be at least 6 calibration points for the 3D DLT and 4 for the 2D DLT.\n",
    "    Outputs:\n",
    "     L: array of the 8 or 11 parameters of the calibration matrix\n",
    "     err: error of the DLT (mean residual of the DLT transformation in units of camera coordinates).\n",
    "    '''\n",
    "    \n",
    "    #Convert all variables to numpy array:\n",
    "    xyz = N.asarray(xyz)\n",
    "    uv = N.asarray(uv)\n",
    "    #number of points:\n",
    "    np = xyz.shape[0]\n",
    "    #Check the parameters:\n",
    "    if uv.shape[0] != np:\n",
    "        raise ValueError('xyz (%d points) and uv (%d points) have different number of points.' %(np, uv.shape[0]))\n",
    "    if (nd == 2 and xyz.shape[1] != 2) or (nd == 3 and xyz.shape[1] != 3):\n",
    "        raise ValueError('Incorrect number of coordinates (%d) for %dD DLT (it should be %d).' %(xyz.shape[1],nd,nd))\n",
    "    if nd == 3 and np < 6 or nd == 2 and np < 4:\n",
    "        raise ValueError('%dD DLT requires at least %d calibration points. Only %d points were entered.' %(nd, 2*nd, np))\n",
    "        \n",
    "    #Normalize the data to improve the DLT quality (DLT is dependent of the system of coordinates).\n",
    "    #This is relevant when there is a considerable perspective distortion.\n",
    "    #Normalization: mean position at origin and mean distance equals to 1 at each direction.\n",
    "    Txyz, xyzn = Normalization(nd, xyz)\n",
    "    Tuv, uvn = Normalization(2, uv)\n",
    "\n",
    "    A = []\n",
    "    if nd == 2: #2D DLT\n",
    "        for i in range(np):\n",
    "            x,y = xyzn[i,0], xyzn[i,1]\n",
    "            u,v = uvn[i,0], uvn[i,1]\n",
    "            A.append( [x, y, 1, 0, 0, 0, -u*x, -u*y, -u] )\n",
    "            A.append( [0, 0, 0, x, y, 1, -v*x, -v*y, -v] )\n",
    "    elif nd == 3: #3D DLT\n",
    "        for i in range(np):\n",
    "            x,y,z = xyzn[i,0], xyzn[i,1], xyzn[i,2]\n",
    "            u,v = uvn[i,0], uvn[i,1]\n",
    "            A.append( [x, y, z, 1, 0, 0, 0, 0, -u*x, -u*y, -u*z, -u] )\n",
    "            A.append( [0, 0, 0, 0, x, y, z, 1, -v*x, -v*y, -v*z, -v] )\n",
    "\n",
    "    #convert A to array\n",
    "    A = N.asarray(A) \n",
    "    #Find the 11 (or 8 for 2D DLT) parameters:\n",
    "    U, S, Vh = N.linalg.svd(A)\n",
    "    #The parameters are in the last line of Vh and normalize them:\n",
    "    L = Vh[-1,:] / Vh[-1,-1]\n",
    "    #Camera projection matrix:\n",
    "    H = L.reshape(3,nd+1)\n",
    "    #Denormalization:\n",
    "    H = N.dot( N.dot( N.linalg.pinv(Tuv), H ), Txyz );\n",
    "    H = H / H[-1,-1]\n",
    "    L = H.flatten(0)\n",
    "    #Mean error of the DLT (mean residual of the DLT transformation in units of camera coordinates):\n",
    "    uv2 = N.dot( H, N.concatenate( (xyz.T, N.ones((1,xyz.shape[0]))) ) ) \n",
    "    uv2 = uv2/uv2[2,:] \n",
    "    #mean distance:\n",
    "    err = N.sqrt( N.mean(N.sum( (uv2[0:2,:].T - uv)**2,1 )) ) \n",
    "\n",
    "    return L, err\n",
    "\n",
    "\n",
    "def Normalization(nd,x):\n",
    "    '''\n",
    "    Normalization of coordinates (centroid to the origin and mean distance of sqrt(2 or 3).\n",
    "\n",
    "    Inputs:\n",
    "     nd: number of dimensions (2 for 2D; 3 for 3D)\n",
    "     x: the data to be normalized (directions at different columns and points at rows)\n",
    "    Outputs:\n",
    "     Tr: the transformation matrix (translation plus scaling)\n",
    "     x: the transformed data\n",
    "    '''\n",
    "\n",
    "    x = N.asarray(x)\n",
    "    m, s = N.mean(x,0), N.std(x)\n",
    "    if nd==2:\n",
    "        Tr = N.array([[s, 0, m[0]], [0, s, m[1]], [0, 0, 1]])\n",
    "    else:\n",
    "        Tr = N.array([[s, 0, 0, m[0]], [0, s, 0, m[1]], [0, 0, s, m[2]], [0, 0, 0, 1]])\n",
    "        \n",
    "    Tr = N.linalg.inv(Tr)\n",
    "    x = N.dot( Tr, N.concatenate( (x.T, N.ones((1,x.shape[0]))) ) )\n",
    "    x = x[0:nd,:].T\n",
    "\n",
    "    return Tr, x\n",
    "\n",
    "\n",
    "def test():\n",
    "    #Tests of DLTx \n",
    "    print('')\n",
    "    print('Test of camera calibration and point reconstruction based on direct linear transformation (DLT).')\n",
    "    print('3D (x, y, z) coordinates (in cm) of the corner of a cube (the measurement error is at least 0.2 cm):')\n",
    "    xyz = [[0,0,0], [0,12.3,0], [14.5,12.3,0], [14.5,0,0], [0,0,14.5], [0,12.3,14.5], [14.5,12.3,14.5], [14.5,0,14.5]]\n",
    "    print(N.asarray(xyz))\n",
    "    print('2D (u, v) coordinates (in pixels) of 4 different views of the cube:')\n",
    "    uv1 = [[1302,1147],[1110,976],[1411,863],[1618,1012],[1324,812],[1127,658],[1433,564],[1645,704]]\n",
    "    uv2 = [[1094,1187],[1130,956],[1514,968],[1532,1187],[1076,854],[1109,647],[1514,659],[1523,860]]\n",
    "    # uv3 = [[1073,866],[1319,761],[1580,896],[1352,1016],[1064,545],[1304,449],[1568,557],[1313,668]]\n",
    "    # uv4 = [[1205,1511],[1193,1142],[1601,1121],[1631,1487],[1157,1550],[1139,1124],[1628,1100],[1661,1520]]\n",
    "    print('uv1:')\n",
    "    print(N.asarray(uv1))\n",
    "    print('uv2:')\n",
    "    print(N.asarray(uv2))\n",
    "\n",
    "    print('')\n",
    "    print('Use 4 views to perform a 3D calibration of the camera with 8 points of the cube:')\n",
    "    nd=3\n",
    "    nc=4\n",
    "    L1, err1 = DLTcalib(nd, xyz, uv1)\n",
    "    print('Camera calibration parameters based on view #1:')\n",
    "    print(L1)\n",
    "    print('Error of the calibration of view #1 (in pixels):')\n",
    "    print(err1)\n",
    "    L2, err2 = DLTcalib(nd, xyz, uv2)\n",
    "    print('Camera calibration parameters based on view #2:')\n",
    "    print(L2)\n",
    "    print('Error of the calibration of view #2 (in pixels):')\n",
    "    print(err2)\n",
    "    xyz1234 = N.zeros((len(xyz),3))\n",
    "    L1234 = [L1,L2]\n",
    "    for i in range(len(uv1)):\n",
    "        xyz1234[i,:] = DLTrecon( nd, nc, L1234, [uv1[i],uv2[i]] )\n",
    "    print('Reconstruction of the same 8 points based on 4 views and the camera calibration parameters:')\n",
    "    print(xyz1234)\n",
    "    print('Mean error of the point reconstruction using the DLT (error in cm):')\n",
    "    print(N.mean(N.sqrt(N.sum((N.array(xyz1234)-N.array(xyz))**2,1))))\n",
    "\n",
    "    print('')\n",
    "    print('Test of the 2D DLT')\n",
    "    print('2D (x, y) coordinates (in cm) of the corner of a square (the measurement error is at least 0.2 cm):')\n",
    "    xy = [[0,0], [0,12.3], [14.5,12.3], [14.5,0]]\n",
    "    print(N.asarray(xy))\n",
    "    print('2D (u, v) coordinates (in pixels) of 2 different views of the square:')\n",
    "    uv1 = [[1302,1147],[1110,976],[1411,863],[1618,1012]]\n",
    "    uv2 = [[1094,1187],[1130,956],[1514,968],[1532,1187]]\n",
    "    print('uv1:')\n",
    "    print(N.asarray(uv1))\n",
    "    print('uv2:')\n",
    "    print(N.asarray(uv2))\n",
    "    print('')\n",
    "    print('Use 2 views to perform a 2D calibration of the camera with 4 points of the square:')\n",
    "    nd=2\n",
    "    nc=2\n",
    "    L1, err1 = DLTcalib(nd, xy, uv1)\n",
    "    print('Camera calibration parameters based on view #1:')\n",
    "    print(L1)\n",
    "    print('Error of the calibration of view #1 (in pixels):')\n",
    "    print(err1)\n",
    "    L2, err2 = DLTcalib(nd, xy, uv2)\n",
    "    print('Camera calibration parameters based on view #2:')\n",
    "    print(L2)\n",
    "    print('Error of the calibration of view #2 (in pixels):')\n",
    "    print(err2)\n",
    "    xy12 = N.zeros((len(xy),2))\n",
    "    L12 = [L1,L2]\n",
    "    for i in range(len(uv1)):\n",
    "        xy12[i,:] = DLTrecon( nd, nc, L12, [uv1[i],uv2[i]] )\n",
    "    print('Reconstruction of the same 4 points based on 2 views and the camera calibration parameters:')\n",
    "    print(xy12)\n",
    "    print('Mean error of the point reconstruction using the DLT (error in cm):')\n",
    "    print(N.mean(N.sqrt(N.sum((N.array(xy12)-N.array(xy))**2,1))))\n",
    "\n",
    "    print('')\n",
    "    print('Use only one view to perform a 2D calibration of the camera with 4 points of the square:')\n",
    "    nd=2\n",
    "    nc=1\n",
    "    L1, err1 = DLTcalib(nd, xy, uv1)\n",
    "    print('Camera calibration parameters based on view #1:')\n",
    "    print(L1)\n",
    "    print('Error of the calibration of view #1 (in pixels):')\n",
    "    print(err1)\n",
    "    xy1 = N.zeros((len(xy),2))\n",
    "    for i in range(len(uv1)):\n",
    "        xy1[i,:] = DLTrecon( nd, nc, L1, uv1[i] )\n",
    "    print('Reconstruction of the same 4 points based on one view and the camera calibration parameters:')\n",
    "    print(xy1)\n",
    "    print('Mean error of the point reconstruction using the DLT (error in cm):')\n",
    "    print(N.mean(N.sqrt(N.sum((N.array(xy1)-N.array(xy))**2,1))))\n",
    "\n",
    "#test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x` y` is -> (276, 462)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (269, 428) (276, 462)\n",
      "DLT -> [ 0.31604726 -0.01208074  0.39756499  1.        ]\n",
      "[ 0.31604726 -0.01208074  0.39756499  1.        ]\n",
      "The x` y` is -> (504, 159)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (281, 140) (504, 159)\n",
      "DLT -> [-65.32553232 -49.28434046   3.84945846   1.        ]\n",
      "[-65.32553232 -49.28434046   3.84945846   1.        ]\n",
      "The x` y` is -> (288, 143)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (278, 160) (288, 143)\n",
      "DLT -> [ 1.61454815e-03 -1.53728947e-01  2.09763563e+01  1.00000000e+00]\n",
      "[ 1.61454815e-03 -1.53728947e-01  2.09763563e+01  1.00000000e+00]\n",
      "The x` y` is -> (288, 177)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (279, 189) (288, 177)\n",
      "DLT -> [-0.2187001  -0.5256915  18.68510643  1.        ]\n",
      "[-0.2187001  -0.5256915  18.68510643  1.        ]\n",
      "The x` y` is -> (286, 80)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (278, 107) (286, 80)\n",
      "DLT -> [-0.62908027 -0.41590869 24.90328088  1.        ]\n",
      "[-0.62908027 -0.41590869 24.90328088  1.        ]\n",
      "The x` y` is -> (348, 187)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (319, 197) (348, 187)\n",
      "DLT -> [ 5.91344413 -0.12884513 18.87076337  1.        ]\n",
      "[ 5.91344413 -0.12884513 18.87076337  1.        ]\n",
      "The x` y` is -> (284, 230)\n",
      "DLT init with [[ 1.28673583e+01 -7.08022740e+00  7.63836385e-01  2.65973053e+02]\n",
      " [ 5.08216216e+00  3.26684766e+00 -1.28100321e+01  4.33572278e+02]\n",
      " [ 1.74581891e-02  1.32772730e-02  1.01479673e-03  1.00000000e+00]] [[ 1.68842575e+01 -5.62662744e+00  9.04067042e-01  2.71937127e+02]\n",
      " [ 5.45493675e+00  4.64392705e+00 -1.54990574e+01  4.69532175e+02]\n",
      " [ 1.82295905e-02  1.83503709e-02  7.30324632e-04  1.00000000e+00]] (275, 234) (284, 230)\n",
      "DLT -> [-0.05851067 -0.19423587 15.28306965  1.        ]\n",
      "[-0.05851067 -0.19423587 15.28306965  1.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def camera_calibration1(image_points, world_points):\n",
    "    # Ensure the inputs are numpy arrays\n",
    "    # image_points = np.array(image_points)\n",
    "    # world_points = np.array(world_points)\n",
    "\n",
    "    # Initialize the matrix A\n",
    "    A = np.zeros((len(image_points) * 2, 12))\n",
    "    \n",
    "    # Fill the matrix A using image and world points\n",
    "    for i, (image, object) in enumerate(zip(image_points, world_points)):\n",
    "        X, Y, Z = object\n",
    "        x, y = image\n",
    "        A[2 * i, :] = [-X, -Y, -Z, -1, 0, 0, 0, 0, x * X, x * Y, x * Z, x]\n",
    "        A[2 * i + 1, :] = [0, 0, 0, 0, -X, -Y, -Z, -1, y * X, y * Y, y * Z, y]\n",
    "\n",
    "    # Perform SVD decomposition\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    \n",
    "    # Get the last row of V and reshape it into a 3x4 matrix to get the projection matrix P\n",
    "    P1 = V[-1].reshape((3, 4))\n",
    "\n",
    "    # Compute the calibration error (reprojection error)\n",
    "    projection_error = 0.0\n",
    "    for image, object in zip(image_points, world_points):\n",
    "        X = np.array(list(object) + [1])\n",
    "        x = np.array(list(image) + [1])\n",
    "        projected_x = np.dot(P, X)\n",
    "        projected_x /= projected_x[-1]  # Normalizing\n",
    "        projection_error += np.linalg.norm(projected_x[:-1] - x[:-1])\n",
    "\n",
    "    mean_error = projection_error / len(image_points)\n",
    "    print(\"Mean reprojection error: {}\".format(mean_error))\n",
    "    print(f\"Projection Matrix: \\n{P}\")\n",
    "    \n",
    "    return P\n",
    "\n",
    "\n",
    "def camera_calibration(image_points, world_points):\n",
    "    num_points = len(image_points)\n",
    "    A = np.zeros((2 * num_points, 12))\n",
    "\n",
    "    for i, (img_pt, obj_pt) in enumerate(zip(image_points, world_points)):\n",
    "        x, y, z = obj_pt\n",
    "        u, v = img_pt\n",
    "\n",
    "        A[2 * i] = [-x, -y, -z, -1, 0, 0, 0, 0, u * x, u * y, u * z, u]\n",
    "        A[2 * i + 1] = [0, 0, 0, 0, -x, -y, -z, -1, v * x, v * y, v * z, v]\n",
    "\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    P = V[-1].reshape((3, 4))\n",
    "    P /= P[-1, -1]  # Normalize\n",
    "\n",
    "    return P\n",
    "\n",
    "# 2D image points\n",
    "image_points = np.array([\n",
    "    [252, 380],\n",
    "    [84, 352],\n",
    "    [92, 202],\n",
    "    [259, 190],\n",
    "    [407, 356],\n",
    "    [294, 379],\n",
    "    [300, 195],\n",
    "    [411, 219]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 3D object points\n",
    "object_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "image_points2 = np.array([\n",
    "    [258, 405],\n",
    "    [105, 364],\n",
    "    [114, 198],\n",
    "    [268, 178],\n",
    "    [474, 376],\n",
    "    [313, 403],\n",
    "    [322, 183],\n",
    "    [480, 213]\n",
    "], dtype=np.float32)\n",
    "\n",
    "P1 = camera_calibration(image_points, object_points)\n",
    "P2 = camera_calibration(image_points2, object_points)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def DLT(P1, P2, p1, p2):\n",
    "    A = np.zeros((4, 4))\n",
    "    A[0] = p1[0] * P1[2, :] - P1[0, :]\n",
    "    A[1] = p1[1] * P1[2, :] - P1[1, :]\n",
    "    A[2] = p2[0] * P2[2, :] - P2[0, :]\n",
    "    A[3] = p2[1] * P2[2, :] - P2[1, :]\n",
    "\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    X = V[-1]\n",
    "    X /= X[3]\n",
    "    print(f\"DLT -> {X}\")\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def find_best_match(src_point, F, img1, img2, window_size=5):\n",
    "    src_point = np.array([src_point], dtype=np.float32)\n",
    "    line = cv2.computeCorrespondEpilines(src_point, 1, F)[0].ravel()\n",
    "    \n",
    "    height, width = img2.shape\n",
    "    \n",
    "    best_score = -1\n",
    "    best_point = None\n",
    "    for x in range(width):\n",
    "        y = int(-(line[2] + line[0] * x) / line[1])\n",
    "        if 0 <= y < height:\n",
    "            y_int = int(src_point[0][1])\n",
    "            x_int = int(src_point[0][0])\n",
    "\n",
    "            window_centered_at_p = img1[y_int-window_size:y_int+window_size+1, \n",
    "                            x_int-window_size:x_int+window_size+1]\n",
    "            window_centered_at_q = img2[y-window_size:y+window_size+1, x-window_size:x+window_size+1]\n",
    "            \n",
    "            if window_centered_at_p.shape == window_centered_at_q.shape:\n",
    "                score = zncc(window_centered_at_p, window_centered_at_q)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_point = (x, y)\n",
    "    \n",
    "    return best_point\n",
    "\n",
    "def zncc(window1, window2):\n",
    "    mean1 = np.mean(window1)\n",
    "    mean2 = np.mean(window2)\n",
    "    \n",
    "    numerator = np.sum((window1 - mean1) * (window2 - mean2))\n",
    "    denominator = np.sqrt(np.sum((window1 - mean1) ** 2) * np.sum((window2 - mean2) ** 2))\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator / denominator\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        F, img1, img2, points1, points2 = param\n",
    "        \n",
    "        dst_point = find_best_match((x, y), F, img1, img2)\n",
    "        cv2.drawMarker(img1, (x, y), (255, 255, 59), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(img2, dst_point, (255, 255, 59), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # cv2.circle(img1, (x, y), 5, (0, 255, 0), -1)\n",
    "        # cv2.circle(img2, dst_point, 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw the epipolar line on the right image\n",
    "        line = cv2.computeCorrespondEpilines(np.array([[x, y]]).reshape(-1, 1, 2), 1, F).reshape(-1,)\n",
    "        color = (255, 0, 0)  # Blue color for the epipolar line\n",
    "        x0, y0 = map(int, [0, -line[2] / line[1]])\n",
    "        x1, y1 = map(int, [img2.shape[1], -(line[2] + line[0] * img2.shape[1]) / line[1]])\n",
    "        cv2.line(img2, (x0, y0), (x1, y1), color, 1)\n",
    "        print(f\"The x` y` is -> {dst_point}\")\n",
    "        print(f\"DLT init with {P1} {P2} {(x, y)} {dst_point}\")\n",
    "        print(DLT(P1, P2, (x,y), dst_point))\n",
    "        cv2.imshow('Image1', img1)\n",
    "        cv2.imshow('Image2', img2)\n",
    "\n",
    "\n",
    "img1 = cv2.imread('im1.jpeg', 0)\n",
    "img2 = cv2.imread('im2.jpeg', 0)\n",
    "\n",
    "\n",
    "keypoints1, descriptors1 = cv2.SIFT_create().detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = cv2.SIFT_create().detectAndCompute(img2, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "matches = bf.match(descriptors1, descriptors2)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "points1 = np.float32([keypoints1[match.queryIdx].pt for match in matches]).reshape(-1, 1, 2)\n",
    "points2 = np.float32([keypoints2[match.trainIdx].pt for match in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "F, mask = cv2.findFundamentalMat(points1, points2, cv2.FM_LMEDS)\n",
    "\n",
    "\n",
    "cv2.namedWindow('Image1')\n",
    "cv2.setMouseCallback('Image1', on_mouse_click, [F, img1, img2, points1, points2])\n",
    "\n",
    "cv2.imshow('Image1', img1)\n",
    "cv2.imshow('Image2', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
