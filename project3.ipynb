{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find chessboard corners in one or both images.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the stereo images\n",
    "left_img = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "right_img = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the number of inner corners of the chessboard (for example, an 8x8 chessboard has 7x7 inner corners)\n",
    "pattern_size = (7, 7)\n",
    "\n",
    "# Find the chessboard corners in both images\n",
    "ret_left, corners_left = cv2.findChessboardCorners(left_img, pattern_size)\n",
    "ret_right, corners_right = cv2.findChessboardCorners(right_img, pattern_size)\n",
    "\n",
    "if ret_left and ret_right:\n",
    "    # Refine the detected corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    cv2.cornerSubPix(left_img, corners_left, (11, 11), (-1, -1), criteria)\n",
    "    cv2.cornerSubPix(right_img, corners_right, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "    # These are your 2D points in each image\n",
    "    points_2d_left = corners_left\n",
    "    points_2d_right = corners_right\n",
    "else:\n",
    "    print(\"Could not find chessboard corners in one or both images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "right_img = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.findChessboardCorners(left_img, (7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load Images\n",
    "img1 = cv2.imread(\"first_image.jpg\")\n",
    "img2 = cv2.imread(\"second_image.jpg\")\n",
    "\n",
    "# 2. Given 3D points and corresponding 2D points\n",
    "# Replace with your data\n",
    "object_points_left = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "])\n",
    "\n",
    "object_points_right = np.array([\n",
    "    [24.3, 0, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "])\n",
    "\n",
    "# 3. Get 2D points (e.g., clicked on the images or detected automatically)\n",
    "# For demonstration, let's assume they are:\n",
    "image_points_left = np.array([\n",
    "    # Example points, replace with detected coordinates\n",
    "    [100, 100],\n",
    "    [200, 100],\n",
    "    [200, 200],\n",
    "    [100, 200],\n",
    "    [100, 50],\n",
    "    [200, 50],\n",
    "    [200, 250],\n",
    "    [100, 250]\n",
    "])\n",
    "\n",
    "image_points_right = image_points_left + 5  # Just for demo, consider it's shifted by 5 pixels\n",
    "\n",
    "# 4. Camera Calibration\n",
    "_, camera_matrix_left, dist_coeff_left, _, _ = cv2.calibrateCamera([object_points], [image_points_left], img1.shape[:2], None, None)\n",
    "_, camera_matrix_right, dist_coeff_right, _, _ = cv2.calibrateCamera([object_points], [image_points_right], img2.shape[:2], None, None)\n",
    "\n",
    "# 5. Calculate Fundamental Matrix\n",
    "F, _ = cv2.findFundamentalMat(image_points_left, image_points_right, cv2.FM_LMEDS)\n",
    "\n",
    "# 6. Triangulation to get 3D coordinates\n",
    "def triangulate_points(p1, p2, m1, m2):\n",
    "    return cv2.triangulatePoints(m1, m2, p1.T, p2.T).T\n",
    "\n",
    "# 7. Mouse Callback Function\n",
    "def callback(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        p1 = np.array([x, y, 1]).reshape(3, 1)\n",
    "        \n",
    "        # Draw a + sign at p\n",
    "        cv2.drawMarker(img1, (x, y), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10)\n",
    "        \n",
    "        # Compute epipolar line on right image\n",
    "        l2 = np.dot(F, p1)\n",
    "        x0, y0 = map(int, [0, -l2[2]/l2[1]])\n",
    "        x1, y1 = map(int, [img2.shape[1], -(l2[2] + l2[0]*img2.shape[1]) / l2[1]])\n",
    "        \n",
    "        # Draw the line on the right image\n",
    "        cv2.line(img2, (x0, y0), (x1, y1), (0, 255, 0), 1)\n",
    "        \n",
    "        # This is a naive way to find a corresponding point. In real-world applications, you'd use better matching techniques.\n",
    "        p2 = np.array([x+5, y, 1]).reshape(3, 1)  # Assuming the shift is 5 pixels for demonstration\n",
    "        \n",
    "        # Draw a + sign at p'\n",
    "        cv2.drawMarker(img2, (x+5, y), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10)\n",
    "        \n",
    "        # Get 3D coordinates\n",
    "        point_3d_homo = triangulate_points(p1.T, p2.T, camera_matrix_left, camera_matrix_right)\n",
    "        point_3d = (point_3d_homo / point_3d_homo[3])[:3].ravel()\n",
    "        \n",
    "        print(f\"3D Point: {point_3d}\")\n",
    "        \n",
    "        cv2.imshow('Left Image', img1)\n",
    "        cv2.imshow('Right Image', img2)\n",
    "\n",
    "# Create window and bind function to window\n",
    "cv2.namedWindow('Left Image')\n",
    "cv2.setMouseCallback('Left Image', callback)\n",
    "\n",
    "cv2.imshow('Left Image', img1)\n",
    "cv2.imshow('Right Image', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in left image: [(253, 378), (85, 351), (92, 200), (260, 192), (407, 356), (294, 378), (301, 196), (413, 220)]\n",
      "Points in right image: [(257, 404), (106, 365), (113, 197), (269, 177), (475, 376), (312, 402), (321, 184), (480, 214)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Global variables\n",
    "point_list = []\n",
    "point_count = 0\n",
    "\n",
    "# Mouse callback function\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global point_list, point_count\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(temp_img, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Image', temp_img)\n",
    "        point_list.append((x, y))\n",
    "        point_count += 1\n",
    "\n",
    "        if point_count == 18:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Read your image\n",
    "img_left = cv2.imread('im1.jpeg')\n",
    "img_right = cv2.imread('im2.jpeg')\n",
    "\n",
    "# For left image\n",
    "temp_img = img_left.copy()\n",
    "cv2.imshow('Image', temp_img)\n",
    "cv2.setMouseCallback('Image', select_points)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "points_2d_left = point_list.copy()  # save the points for the left image\n",
    "point_list.clear()  # clear the list to store points for the right image\n",
    "point_count = 0  # reset point count\n",
    "\n",
    "# For right image\n",
    "temp_img = img_right.copy()\n",
    "cv2.imshow('Image', temp_img)\n",
    "cv2.setMouseCallback('Image', select_points)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "points_2d_right = point_list\n",
    "\n",
    "print(\"Points in left image:\", points_2d_left)\n",
    "print(\"Points in right image:\", points_2d_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m points_2d_right \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([(\u001b[39m475\u001b[39m, \u001b[39m373\u001b[39m), (\u001b[39m312\u001b[39m, \u001b[39m402\u001b[39m), (\u001b[39m323\u001b[39m, \u001b[39m185\u001b[39m), (\u001b[39m478\u001b[39m, \u001b[39m214\u001b[39m)], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Camera Calibration\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m ret, mtx_left, dist_left, rvecs_left, tvecs_left \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([world_points_left], [points_2d_left], (\u001b[39m1280\u001b[39;49m, \u001b[39m720\u001b[39;49m), intrinsic_matrix, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     38\u001b[0m ret, mtx_right, dist_right, rvecs_right, tvecs_right \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([world_points_right], [points_2d_right], (\u001b[39m1280\u001b[39m, \u001b[39m720\u001b[39m), intrinsic_matrix, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Calculate Fundamental Matrix\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "world_points_left = np.array([\n",
    "    [  0.        ,  14.46666667,   3.8       ],\n",
    "       [  0.        , 217.        ,   3.8       ],\n",
    "       [  0.        , 217.        ,  18.8       ],\n",
    "       [  0.        ,  14.46666667,  18.8       ],\n",
    "], dtype=np.float32)\n",
    "\n",
    "world_points_right = np.array([\n",
    " [394.        ,   0.        ,   3.8       ],\n",
    "       [ 53.50617284,   0.        ,   3.8       ],\n",
    "       [ 53.50617284,   0.        ,  18.8       ],\n",
    "       [394.        ,   0.        ,  18.8       ],\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Image dimensions\n",
    "width = 1280\n",
    "height = 720\n",
    "\n",
    "# Approximate intrinsic matrix\n",
    "fx = width\n",
    "fy = height\n",
    "cx = width / 2\n",
    "cy = height / 2\n",
    "intrinsic_matrix = np.array([[fx, 0, cx],\n",
    "                             [0, fy, cy],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "points_2d_left = np.array([(251, 379), (84, 352), (91, 201), (259, 190)], dtype=np.float32)\n",
    "points_2d_right = np.array([(475, 373), (312, 402), (323, 185), (478, 214)], dtype=np.float32)\n",
    "\n",
    "# Camera Calibration\n",
    "ret, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera([world_points_left], [points_2d_left], (1280, 720), intrinsic_matrix, None)\n",
    "ret, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera([world_points_right], [points_2d_right], (1280, 720), intrinsic_matrix, None)\n",
    "\n",
    "# Calculate Fundamental Matrix\n",
    "F, _ = cv2.findFundamentalMat(points_2d_left, points_2d_right, cv2.FM_8POINT)\n",
    "\n",
    "print(\"Fundamental Matrix F:\\n\", F)\n",
    "\n",
    "# Callback function for mouse click on the left image\n",
    "def on_click_left(event, x, y, flags, param):\n",
    "    global points_2d_left, points_2d_right, mtx_left, mtx_right, F\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pt = np.array([x, y, 1]).reshape(3, 1)\n",
    "        epiline = np.dot(F, pt).ravel()\n",
    "\n",
    "        # Draw the epipolar line on the right image\n",
    "        cv2.line(right_img, (0, int(-epiline[2] / epiline[1])), (right_img.shape[1], int(-(epiline[2] + epiline[0] * right_img.shape[1]) / epiline[1])), (0, 0, 255), 1)\n",
    "\n",
    "        # Draw \"+\" on the left image\n",
    "        cv2.drawMarker(left_img, (x, y), (0, 255, 0), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Show the images again\n",
    "        cv2.imshow('Left Image', left_img)\n",
    "        cv2.imshow('Right Image', right_img)\n",
    "\n",
    "# Callback function for mouse click on the right image\n",
    "def on_click_right(event, x, y, flags, param):\n",
    "    global points_2d_left, points_2d_right, mtx_left, mtx_right, F\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pt = np.array([x, y, 1]).reshape(3, 1)\n",
    "        epiline = np.dot(F.T, pt).ravel()\n",
    "\n",
    "        # Draw the epipolar line on the left image\n",
    "        cv2.line(left_img, (0, int(-epiline[2] / epiline[1])), (left_img.shape[1], int(-(epiline[2] + epiline[0] * left_img.shape[1]) / epiline[1])), (0, 0, 255), 1)\n",
    "\n",
    "        # Draw \"+\" on the right image\n",
    "        cv2.drawMarker(right_img, (x, y), (0, 255, 0), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Show the images again\n",
    "        cv2.imshow('Left Image', left_img)\n",
    "        cv2.imshow('Right Image', right_img)\n",
    "\n",
    "# Load your stereo images\n",
    "left_img = cv2.imread('im1.jpeg')\n",
    "right_img = cv2.imread('im2.jpeg')\n",
    "\n",
    "cv2.namedWindow('Left Image')\n",
    "cv2.setMouseCallback('Left Image', on_click_left)\n",
    "cv2.namedWindow('Right Image')\n",
    "cv2.setMouseCallback('Right Image', on_click_right)\n",
    "\n",
    "cv2.imshow('Left Image', left_img)\n",
    "cv2.imshow('Right Image', right_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 3D points:\n",
      "[[ 0.   1.5  3.8]\n",
      " [ 0.  22.5  3.8]\n",
      " [ 0.  22.5 18.8]\n",
      " [ 0.   1.5 18.8]\n",
      " [24.3  0.   3.8]\n",
      " [ 3.3  0.   3.8]\n",
      " [ 3.3  0.  18.8]\n",
      " [24.3  0.  18.8]]\n",
      "\n",
      "Scaled 3D points:\n",
      "[[  0.          14.46666667   3.8       ]\n",
      " [  0.         217.           3.8       ]\n",
      " [  0.         217.          18.8       ]\n",
      " [  0.          14.46666667  18.8       ]\n",
      " [394.           0.           3.8       ]\n",
      " [ 53.50617284   0.           3.8       ]\n",
      " [ 53.50617284   0.          18.8       ]\n",
      " [394.           0.          18.8       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define your 3D and 2D points\n",
    "points_3d = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "])\n",
    "\n",
    "points_2d_left = np.array([(251, 379), (84, 352), (91, 201), (259, 190)])\n",
    "points_2d_right = np.array([(475, 373), (312, 402), (323, 185), (478, 214)])\n",
    "points_2d = np.vstack((points_2d_left, points_2d_right))\n",
    "\n",
    "# Compute 3D range\n",
    "range_3d = np.max(points_3d, axis=0) - np.min(points_3d, axis=0)\n",
    "\n",
    "# Compute 2D range\n",
    "range_2d = np.max(points_2d, axis=0) - np.min(points_2d, axis=0)\n",
    "\n",
    "# Compute scaling factors\n",
    "scale_factors = range_2d / range_3d[:2]\n",
    "\n",
    "# Scale the 3D points\n",
    "points_3d_scaled = points_3d.copy()\n",
    "points_3d_scaled[:, 0] *= scale_factors[0]\n",
    "points_3d_scaled[:, 1] *= scale_factors[1]\n",
    "\n",
    "print(\"Original 3D points:\")\n",
    "print(points_3d)\n",
    "print(\"\\nScaled 3D points:\")\n",
    "print(points_3d_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,  14.46666667,   3.8       ],\n",
       "       [  0.        , 217.        ,   3.8       ],\n",
       "       [  0.        , 217.        ,  18.8       ],\n",
       "       [  0.        ,  14.46666667,  18.8       ],\n",
       "       [394.        ,   0.        ,   3.8       ],\n",
       "       [ 53.50617284,   0.        ,   3.8       ],\n",
       "       [ 53.50617284,   0.        ,  18.8       ],\n",
       "       [394.        ,   0.        ,  18.8       ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_3d_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m flags \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     37\u001b[0m flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCALIB_FIX_INTRINSIC\n\u001b[0;32m---> 38\u001b[0m ret, mtx_left, dist_left, rvecs_left, tvecs_left \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([scaled_3d_points[:\u001b[39m4\u001b[39;49m]], [points_2d_left], (width, height), intrinsic_matrix, dist_coeff, flags\u001b[39m=\u001b[39;49mflags)\n\u001b[1;32m     39\u001b[0m ret, mtx_right, dist_right, rvecs_right, tvecs_right \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([scaled_3d_points[\u001b[39m4\u001b[39m:]], [points_2d_right], (width, height), intrinsic_matrix, dist_coeff, flags\u001b[39m=\u001b[39mflags)\n\u001b[1;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLeft Camera Matrix:\u001b[39m\u001b[39m\"\u001b[39m, mtx_left)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Image dimensions\n",
    "width = 1280\n",
    "height = 720\n",
    "\n",
    "# Initialize intrinsic matrix\n",
    "fx = width\n",
    "fy = height\n",
    "cx = width / 2\n",
    "cy = height / 2\n",
    "intrinsic_matrix = np.array([[fx, 0, cx],\n",
    "                             [0, fy, cy],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Initial distortion coefficients\n",
    "dist_coeff = np.zeros((5,1), dtype=np.float32)\n",
    "\n",
    "# Your 3D and 2D points\n",
    "scaled_3d_points = np.array([\n",
    "    [0, 14.46666667, 3.8],\n",
    "    [0, 217, 3.8],\n",
    "    [0, 217, 18.8],\n",
    "    [0, 14.46666667, 18.8],\n",
    "    [394, 0, 3.8],\n",
    "    [53.50617284, 0, 3.8],\n",
    "    [53.50617284, 0, 18.8],\n",
    "    [394, 0, 18.8]\n",
    "], dtype=np.float32)\n",
    "\n",
    "points_2d_left = np.array([(251, 379), (84, 352), (91, 201), (259, 190)], dtype=np.float32)\n",
    "points_2d_right = np.array([(475, 373), (312, 402), (323, 185), (478, 214)], dtype=np.float32)\n",
    "\n",
    "# Camera Calibration\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "ret, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera([scaled_3d_points[:4]], [points_2d_left], (width, height), intrinsic_matrix, dist_coeff, flags=flags)\n",
    "ret, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera([scaled_3d_points[4:]], [points_2d_right], (width, height), intrinsic_matrix, dist_coeff, flags=flags)\n",
    "\n",
    "print(\"Left Camera Matrix:\", mtx_left)\n",
    "print(\"Right Camera Matrix:\", mtx_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1173: error: (-2:Unspecified error) in function 'void cvFindExtrinsicCameraParams2(const CvMat *, const CvMat *, const CvMat *, const CvMat *, CvMat *, CvMat *, int)'\n> DLT algorithm needs at least 6 points for pose estimation from 3D-2D point correspondences. (expected: 'count >= 6'), where\n>     'count' is 4\n> must be greater than or equal to\n>     '6' is 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# Initial camera matrix - assuming roughly central principal point and aspect ratio = 1\u001b[39;00m\n\u001b[1;32m     39\u001b[0m initial_camera_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m1000\u001b[39m, \u001b[39m0\u001b[39m, image_size[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m, image_size[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]])\n\u001b[0;32m---> 40\u001b[0m ret, mtx_left, dist_left, rvecs_left, tvecs_left \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera([world_points[:\u001b[39m4\u001b[39;49m]], [points_2d_left], image_size, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     41\u001b[0m ret, mtx_right, dist_right, rvecs_right, tvecs_right \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera([world_points[\u001b[39m4\u001b[39m:]], [points_2d_right], image_size, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Compute the fundamental matrix\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1173: error: (-2:Unspecified error) in function 'void cvFindExtrinsicCameraParams2(const CvMat *, const CvMat *, const CvMat *, const CvMat *, CvMat *, CvMat *, int)'\n> DLT algorithm needs at least 6 points for pose estimation from 3D-2D point correspondences. (expected: 'count >= 6'), where\n>     'count' is 4\n> must be greater than or equal to\n>     '6' is 6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Reading the Images\n",
    "left_img = cv2.imread(\"im1.jpeg\")\n",
    "right_img = cv2.imread(\"im2.jpeg\")\n",
    "\n",
    "# Known 3D world points and 2D image points\n",
    "world_points = np.array([\n",
    "    [0, 1.5, 0],\n",
    "    [0, 22.5, 0],\n",
    "    [0, 22.5, 0],\n",
    "    [0, 1.5, 0],\n",
    "    [24.3, 0, 0],\n",
    "    [3.3, 0, 0],\n",
    "    [3.3, 0, 0],\n",
    "    [24.3, 0, 0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "points_2d_left = np.array([\n",
    "    [251, 379], \n",
    "    [84, 352], \n",
    "    [91, 201], \n",
    "    [259, 190]\n",
    "], dtype=np.float32)\n",
    "\n",
    "points_2d_right = np.array([\n",
    "    [475, 373],\n",
    "    [312, 402], \n",
    "    [323, 185], \n",
    "    [478, 214]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Camera calibration\n",
    "# Define image size\n",
    "image_size = (left_img.shape[1], left_img.shape[0])  # (width, height)\n",
    "\n",
    "# Initial camera matrix - assuming roughly central principal point and aspect ratio = 1\n",
    "initial_camera_matrix = np.array([[1000, 0, image_size[0]/2], [0, 1000, image_size[1]/2], [0, 0, 1]])\n",
    "ret, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera([world_points[:4]], [points_2d_left], image_size, None, None)\n",
    "ret, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera([world_points[4:]], [points_2d_right], image_size, None, None)\n",
    "\n",
    "\n",
    "# Compute the fundamental matrix\n",
    "F, _ = cv2.findFundamentalMat(points_2d_left, points_2d_right, cv2.FM_LMEDS)\n",
    "\n",
    "def mouse_event_handler(event, x, y, flags, param):\n",
    "    global left_img, right_img\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if param == \"left\":\n",
    "            cv2.circle(left_img, (x,y), 5, (0,0,255), -1)\n",
    "            \n",
    "            # Calculate epipolar line on the right image\n",
    "            line = cv2.computeCorrespondEpilines(np.array([[x, y]]).reshape(-1,1,2), 1, F)\n",
    "            line = line.squeeze()\n",
    "            start = (0, int(-line[2]/line[1]))\n",
    "            end = (right_img.shape[1], int((-line[2]-line[0]*right_img.shape[1])/line[1]))\n",
    "            \n",
    "            cv2.line(right_img, start, end, (0,255,0), 1)\n",
    "            \n",
    "            # Triangulation to compute 3D coordinates\n",
    "            P1 = np.hstack((mtx_left, np.array([[0], [0], [0]])))\n",
    "            P2 = np.hstack((mtx_right, np.array([[0], [0], [0]])))\n",
    "\n",
    "            point_4d_hom = cv2.triangulatePoints(P1, P2, np.array([[x], [y]]), np.array([[x], [y]]))  # You may need to adjust the corresponding point in the right image\n",
    "            point_3d = point_4d_hom / point_4d_hom[3]\n",
    "            print(\"3D Point:\", point_3d[:3])\n",
    "\n",
    "        elif param == \"right\":\n",
    "            # Similar steps for the right image...\n",
    "            cv2.circle(right_img, (x,y), 5, (0,0,255), -1)\n",
    "            \n",
    "            # Calculate epipolar line on the right image\n",
    "            line = cv2.computeCorrespondEpilines(np.array([[x, y]]).reshape(-1,1,2), 1, F)\n",
    "            line = line.squeeze()\n",
    "            start = (0, int(-line[2]/line[1]))\n",
    "            end = (right_img.shape[1], int((-line[2]-line[0]*right_img.shape[1])/line[1]))\n",
    "            \n",
    "            cv2.line(right_img, start, end, (0,255,0), 1)\n",
    "            \n",
    "            # Triangulation to compute 3D coordinates\n",
    "            P1 = np.hstack((mtx_left, np.array([[0], [0], [0]])))\n",
    "            P2 = np.hstack((mtx_right, np.array([[0], [0], [0]])))\n",
    "\n",
    "            point_4d_hom = cv2.triangulatePoints(P1, P2, np.array([[x], [y]]), np.array([[x], [y]]))  # You may need to adjust the corresponding point in the right image\n",
    "            point_3d = point_4d_hom / point_4d_hom[3]\n",
    "            print(\"3D Point:\", point_3d[:3])\n",
    "            pass\n",
    "\n",
    "        cv2.imshow(\"Left Image\", left_img)\n",
    "        cv2.imshow(\"Right Image\", right_img)\n",
    "\n",
    "cv2.namedWindow(\"Left Image\")\n",
    "cv2.namedWindow(\"Right Image\")\n",
    "\n",
    "cv2.setMouseCallback(\"Left Image\", mouse_event_handler, \"left\")\n",
    "cv2.setMouseCallback(\"Right Image\", mouse_event_handler, \"right\")\n",
    "\n",
    "cv2.imshow(\"Left Image\", left_img)\n",
    "cv2.imshow(\"Right Image\", right_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the left and right images in grayscale\n",
    "imgL = cv2.imread('im1.jpeg', 0)\n",
    "imgR = cv2.imread('im2.jpeg', 0)\n",
    "\n",
    "# Use StereoSGBM to calculate disparity\n",
    "window_size = 5\n",
    "min_disp = 32\n",
    "num_disp = 112-min_disp\n",
    "stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "    numDisparities = num_disp,\n",
    "    blockSize = 16,\n",
    "    P1 = 8*3*window_size**2,\n",
    "    P2 = 32*3*window_size**2,\n",
    "    disp12MaxDiff = 1,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = stereo.compute(imgL,imgR).astype(np.float32) / 16.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       ...,\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.],\n",
       "       [31., 31., 31., ..., 31., 31., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = imgL.shape[:2]\n",
    "f = 0.8 * w  # guess for focal length\n",
    "Q = np.float32([[1, 0, 0, -0.5 * w],\n",
    "                    [0, -1, 0, 0.5 * h],  # turn points 180 deg around x-axis,\n",
    "                    [0, 0, 0, -f],  # so that y-axis looks up\n",
    "                    [0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = cv2.reprojectImageTo3D(disparity, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-10.32258  ,   7.7419353, -16.516129 ],\n",
       "        [-10.290322 ,   7.7419353, -16.516129 ],\n",
       "        [-10.258064 ,   7.7419353, -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,   7.7419353, -16.516129 ],\n",
       "        [ 10.258064 ,   7.7419353, -16.516129 ],\n",
       "        [ 10.290322 ,   7.7419353, -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,   7.709677 , -16.516129 ],\n",
       "        [-10.290322 ,   7.709677 , -16.516129 ],\n",
       "        [-10.258064 ,   7.709677 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,   7.709677 , -16.516129 ],\n",
       "        [ 10.258064 ,   7.709677 , -16.516129 ],\n",
       "        [ 10.290322 ,   7.709677 , -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,   7.677419 , -16.516129 ],\n",
       "        [-10.290322 ,   7.677419 , -16.516129 ],\n",
       "        [-10.258064 ,   7.677419 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,   7.677419 , -16.516129 ],\n",
       "        [ 10.258064 ,   7.677419 , -16.516129 ],\n",
       "        [ 10.290322 ,   7.677419 , -16.516129 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-10.32258  ,  -7.645161 , -16.516129 ],\n",
       "        [-10.290322 ,  -7.645161 , -16.516129 ],\n",
       "        [-10.258064 ,  -7.645161 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,  -7.645161 , -16.516129 ],\n",
       "        [ 10.258064 ,  -7.645161 , -16.516129 ],\n",
       "        [ 10.290322 ,  -7.645161 , -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,  -7.677419 , -16.516129 ],\n",
       "        [-10.290322 ,  -7.677419 , -16.516129 ],\n",
       "        [-10.258064 ,  -7.677419 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,  -7.677419 , -16.516129 ],\n",
       "        [ 10.258064 ,  -7.677419 , -16.516129 ],\n",
       "        [ 10.290322 ,  -7.677419 , -16.516129 ]],\n",
       "\n",
       "       [[-10.32258  ,  -7.709677 , -16.516129 ],\n",
       "        [-10.290322 ,  -7.709677 , -16.516129 ],\n",
       "        [-10.258064 ,  -7.709677 , -16.516129 ],\n",
       "        ...,\n",
       "        [ 10.225806 ,  -7.709677 , -16.516129 ],\n",
       "        [ 10.258064 ,  -7.709677 , -16.516129 ],\n",
       "        [ 10.290322 ,  -7.709677 , -16.516129 ]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_img\n",
    "cv2.findChessboardCorners(left_img, (8,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[103, 103, 103],\n",
       "        [103, 103, 103],\n",
       "        [103, 103, 103],\n",
       "        ...,\n",
       "        [ 52,  52,  52],\n",
       "        [ 42,  42,  42],\n",
       "        [ 62,  62,  62]],\n",
       "\n",
       "       [[104, 104, 104],\n",
       "        [103, 103, 103],\n",
       "        [104, 104, 104],\n",
       "        ...,\n",
       "        [ 52,  52,  52],\n",
       "        [ 42,  42,  42],\n",
       "        [ 65,  65,  65]],\n",
       "\n",
       "       [[102, 102, 102],\n",
       "        [101, 101, 101],\n",
       "        [104, 104, 104],\n",
       "        ...,\n",
       "        [ 52,  52,  52],\n",
       "        [ 41,  41,  41],\n",
       "        [ 67,  67,  67]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 43,  43,  43],\n",
       "        [ 45,  45,  45],\n",
       "        [ 46,  46,  46],\n",
       "        ...,\n",
       "        [ 29,  29,  29],\n",
       "        [ 29,  29,  29],\n",
       "        [ 27,  27,  27]],\n",
       "\n",
       "       [[ 45,  45,  45],\n",
       "        [ 45,  45,  45],\n",
       "        [ 51,  51,  51],\n",
       "        ...,\n",
       "        [ 28,  28,  28],\n",
       "        [ 29,  29,  29],\n",
       "        [ 27,  27,  27]],\n",
       "\n",
       "       [[ 46,  46,  46],\n",
       "        [ 48,  48,  48],\n",
       "        [ 55,  55,  55],\n",
       "        ...,\n",
       "        [ 31,  31,  31],\n",
       "        [ 30,  30,  30],\n",
       "        [ 29,  29,  29]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "left = cv2.imread('im1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "cv2.findChessboardCornersSBWithMeta(gray, (6,4), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     18\u001b[0m points_2d_left \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m     19\u001b[0m     (\u001b[39m251\u001b[39m, \u001b[39m379\u001b[39m),\n\u001b[1;32m     20\u001b[0m     (\u001b[39m84\u001b[39m, \u001b[39m352\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     (\u001b[39m411\u001b[39m, \u001b[39m219\u001b[39m),\n\u001b[1;32m     27\u001b[0m ], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Calibrate the camera\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m ret, mtx, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalibrateCamera(world_points, points_2d_left, (\u001b[39m1280\u001b[39;49m, \u001b[39m720\u001b[39;49m), \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# Print the camera matrix\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera Matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:1576: error: (-5:Bad argument) For non-planar calibration rigs the initial intrinsic matrix must be specified in function 'cvCalibrateCamera2Internal'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define 3D world coordinates of 4 known points\n",
    "world_points = np.array([\n",
    "    [0, 1.5, 3.8],\n",
    "    [0, 22.5, 3.8],\n",
    "    [0, 22.5, 18.8],\n",
    "    [0, 1.5, 18.8],\n",
    "    [24.3, 0, 3.8],\n",
    "    [3.3, 0, 3.8],\n",
    "    [3.3, 0, 18.8],\n",
    "    [24.3, 0, 18.8]\n",
    "], dtype=np.float32).reshape(1, -1, 3)\n",
    "\n",
    "# Define corresponding 2D image points\n",
    "#407 356 \n",
    "points_2d_left = np.array([\n",
    "    (251, 379),\n",
    "    (84, 352),\n",
    "    (91, 201),\n",
    "    (259, 190),\n",
    "    (407, 356),\n",
    "    (294, 379),\n",
    "    (300, 195),\n",
    "    (411, 219),\n",
    "], dtype=np.float32).reshape(1, -1, 2)\n",
    "\n",
    "# Calibrate the camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(world_points, points_2d_left, (1280, 720), None, None)\n",
    "\n",
    "# Print the camera matrix\n",
    "print(\"Camera Matrix:\")\n",
    "print(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera parameters: \n",
      " [ 1.28673584e+01 -7.08022743e+00  7.63836467e-01  2.65973054e+02\n",
      "  5.08216239e+00  3.26684771e+00 -1.28100314e+01  4.33572277e+02\n",
      "  1.74581898e-02  1.32772732e-02  1.01479734e-03  1.00000000e+00]\n",
      "Mean reprojection error: 0.4362484913196166\n",
      "Camera parameters: \n",
      " [ 1.68842575e+01 -5.62662763e+00  9.04067537e-01  2.71937129e+02\n",
      "  5.45493674e+00  4.64392716e+00 -1.54990563e+01  4.69532176e+02\n",
      "  1.82295906e-02  1.83503713e-02  7.30327158e-04  1.00000000e+00]\n",
      "Mean reprojection error: 0.7810626650427404\n",
      "[[ 1.81027797e-07  4.21788655e-05 -1.18716237e-02]\n",
      " [-4.96572594e-05 -7.02350956e-07  4.55563961e-02]\n",
      " [ 1.39292079e-02 -4.94497562e-02  1.00000000e+00]]\n",
      "the best point (254, 403)\n",
      "3D Reconstruction: [[-13.85506002]\n",
      " [-12.78419918]\n",
      " [ -0.64817932]]\n",
      "the best point (85, 364)\n",
      "3D Reconstruction: [[17.06386603]\n",
      " [ 1.54519934]\n",
      " [ 1.11012526]]\n",
      "the best point (98, 196)\n",
      "3D Reconstruction: [[54.47631393]\n",
      " [52.48770536]\n",
      " [ 2.28063004]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 253\u001b[0m\n\u001b[1;32m    250\u001b[0m cv2\u001b[39m.\u001b[39msetMouseCallback(\u001b[39m'\u001b[39m\u001b[39mImage1\u001b[39m\u001b[39m'\u001b[39m, click_and_mark)\n\u001b[1;32m    252\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     key \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# Press 'q' to quit and save the points\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('im1_points.txt', 'r') as f:\n",
    "    points1 = f.readlines()\n",
    "\n",
    "with open('im2_points.txt', 'r') as f:\n",
    "    points2 = f.readlines()\n",
    "\n",
    "with open('3DCoordinates.txt', 'r') as f:\n",
    "    points_3d = f.readlines()\n",
    "\n",
    "points1 = [point.split() for point in points1]  # 2D image points\n",
    "points2 = [point.split() for point in points2]  # 2D image points\n",
    "points_3d = [point.split() for point in points_3d]  # 3D world points\n",
    "im1 = cv2.imread('im1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "im2 = cv2.imread('im2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "def camera_calibration(image_points, world_points):\n",
    "    A = np.zeros((len(image_points) * 2, 12))\n",
    "    for i, (image, object) in enumerate(zip(image_points, world_points)):\n",
    "        X, Y, Z = [float(point) for point in object]\n",
    "        x, y = [float(point) for point in image]\n",
    "        A[2 * i, :] = [-X, -Y, -Z, -1, 0, 0, 0, 0, x * X, x * Y, x * Z, x]\n",
    "        A[2 * i + 1, :] = [0, 0, 0, 0, -X, -Y, -Z, -1, y * X, y * Y, y * Z, y]\n",
    "    # Perform SVD decomposition\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    P = V[-1].reshape((3, 4))\n",
    "\n",
    "    # Extract camera parameters from V\n",
    "    camera_params = V[-1, :12]\n",
    "    camera_params /= camera_params[-1]  # Normalize the parameters\n",
    "\n",
    "    print(f'Camera parameters: \\n {camera_params}')\n",
    "    # Compute the calibration error\n",
    "    projection_error = 0.0\n",
    "    for i, (image, object) in enumerate(zip(image_points, world_points)):\n",
    "        X = [float(point) for point in object]\n",
    "        X.append(1)\n",
    "        x = [float(point) for point in image]\n",
    "        x.append(1)\n",
    "\n",
    "        projected_x = np.dot(camera_params.reshape((3, 4)), X)\n",
    "        projected_x /= projected_x[-1]  # Normalizing\n",
    "        projection_error += np.linalg.norm(projected_x[:-1] - x[:-1])\n",
    "\n",
    "    mean_error = projection_error / len(image_points)\n",
    "    print(\"Mean reprojection error: {}\".format(mean_error))\n",
    "\n",
    "    return camera_params\n",
    "\n",
    "\n",
    "def calculate_fundamental_matrix(img1, img2):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints and compute descriptors for both images\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Initialize Brute-Force Matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Apply ratio test to keep good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extract corresponding keypoints\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Compute fundamental matrix using RANSAC\n",
    "    fundamental_matrix, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC)\n",
    "\n",
    "    print(fundamental_matrix)\n",
    "    return fundamental_matrix\n",
    "\n",
    "\n",
    "def calculate_zncc(img1, img2, point1, point2, window_size):\n",
    "    \"\"\"\n",
    "    Calculate Zero Mean Normalized Cross-Correlation (ZNCC) between two pixel points.\n",
    "\n",
    "    Args:\n",
    "        img1 (numpy.ndarray): The first image.\n",
    "        img2 (numpy.ndarray): The second image.\n",
    "        point1 (tuple): Coordinates (row, col) of the first point in img1.\n",
    "        point2 (tuple): Coordinates (row, col) of the corresponding point in img2.\n",
    "        window_size (int): Size of the window around the points for ZNCC calculation.\n",
    "\n",
    "    Returns:\n",
    "        zncc_score (float): ZNCC score between the patches centered at the two points.\n",
    "    \"\"\"\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    # Extract patches around the points\n",
    "    patch1 = img1[point1[0] - half_window:point1[0] + half_window + 1,\n",
    "             point1[1] - half_window:point1[1] + half_window + 1]\n",
    "\n",
    "    patch2 = img2[point2[0] - half_window:point2[0] + half_window + 1,\n",
    "             point2[1] - half_window:point2[1] + half_window + 1]\n",
    "\n",
    "    # Calculate means of the patches\n",
    "    mean1 = np.mean(patch1)\n",
    "    mean2 = np.mean(patch2)\n",
    "\n",
    "    # Calculate zero-mean patches\n",
    "    zero_mean_patch1 = patch1 - mean1\n",
    "    zero_mean_patch2 = patch2 - mean2\n",
    "\n",
    "    # Calculate the cross-correlation\n",
    "    cross_corr = np.sum(zero_mean_patch1 * zero_mean_patch2)\n",
    "\n",
    "    # Calculate the standard deviations\n",
    "    std_dev1 = np.sqrt(np.sum(zero_mean_patch1 ** 2))\n",
    "    std_dev2 = np.sqrt(np.sum(zero_mean_patch2 ** 2))\n",
    "\n",
    "    # Calculate ZNCC\n",
    "    zncc_score = cross_corr / (std_dev1 * std_dev2)\n",
    "\n",
    "    return zncc_score\n",
    "\n",
    "\n",
    "def drawEpipolarLine(u, v, F, img1, img2):\n",
    "\n",
    "    p = np.array([[u, v, 1]], dtype=np.float32)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Detect keypoints\n",
    "    keypoints1, desc1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, desc2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Create a Brute-Force Matcher\n",
    "    bf = cv2.BFMatcher()\n",
    "    # Match descriptors from both images\n",
    "    matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "    # Apply ratio test to filter good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.3 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    src_pts = np.float32([keypoints1[match.queryIdx].pt for match in good_matches])\n",
    "    dst_pts = np.float32([keypoints2[match.trainIdx].pt for match in good_matches])\n",
    "\n",
    "    distance_from_keypoints = list()\n",
    "    for i, pt in enumerate(src_pts):\n",
    "        distance_from_keypoints.append((math.sqrt((pt[0] - u)**2 + (pt[1] - v)**2), pt, dst_pts[i]))\n",
    "    distance_from_keypoints.sort(key=lambda x: x[0])\n",
    "    distance_from_keypoints = distance_from_keypoints[0]\n",
    "\n",
    "    disparity = distance_from_keypoints[1][0] - distance_from_keypoints[2][0]\n",
    "\n",
    "    line = cv2.computeCorrespondEpilines(p, 1, F)\n",
    "    epipolar_line = line.reshape(-1, 3)\n",
    "    # Calculate epipolar line parameters\n",
    "    epipolar_line = epipolar_line.flatten()\n",
    "    a, b, c = epipolar_line\n",
    "\n",
    "    # Calculate the range of x coordinates for drawing the line\n",
    "    img1_height, img1_width = img1.shape[:2]\n",
    "    x1 = 0\n",
    "    y1 = int(-c / b)\n",
    "    x2 = img1_width - 1\n",
    "    y2 = int(-(a * x2 + c) / b)\n",
    "\n",
    "    img_with_line = cv2.line(img2, [x1, y1], [x2, y2], (0, 255, 0))\n",
    "\n",
    "    points_right = list()\n",
    "    ranges = [int(u-disparity), int(u+disparity)]\n",
    "    for x in range(min(ranges), max(ranges)):\n",
    "        y = int(-(epipolar_line[0] * x + epipolar_line[2]) / epipolar_line[1])\n",
    "\n",
    "        try:\n",
    "            zncc_score = calculate_zncc(img1, img2, (u, v), (x, y), window_size=7)\n",
    "            points_right.append(((x, y), zncc_score))\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    points_right.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_point_right = points_right[0]\n",
    "\n",
    "    cv2.circle(img_with_line, (best_point_right[0][0], best_point_right[0][1]), 5, (0, 0, 255), -1)\n",
    "    cv2.imshow('Image', img_with_line)\n",
    "    cv2.waitKey(0)\n",
    "    print(f'the best point {best_point_right[0]}')\n",
    "    return best_point_right[0]\n",
    "\n",
    "\n",
    "def three_dimensional_reconstruction(camera_matrix1, camera_matrix2, p1, p2):\n",
    "    A = np.zeros((4, 3))\n",
    "\n",
    "    A[0][0] = p1[0] * camera_matrix1[8] - camera_matrix1[0]\n",
    "    A[0][1] = p1[0] * camera_matrix1[9] - camera_matrix1[1]\n",
    "    A[0][2] = p1[0] * camera_matrix1[10] - camera_matrix1[2]\n",
    "\n",
    "    A[1][0] = p1[1] * camera_matrix1[8] - camera_matrix1[4]\n",
    "    A[1][1] = p1[1] * camera_matrix1[9] - camera_matrix1[5]\n",
    "    A[1][2] = p1[1] * camera_matrix1[10] - camera_matrix1[6]\n",
    "\n",
    "    A[2][0] = p2[0] * camera_matrix2[8] - camera_matrix2[1]\n",
    "    A[2][1] = p2[0] * camera_matrix2[9] - camera_matrix2[2]\n",
    "    A[2][2] = p2[0] * camera_matrix2[10] - camera_matrix2[3]\n",
    "\n",
    "    A[3][0] = p2[0] * camera_matrix2[8] - camera_matrix2[4]\n",
    "    A[3][1] = p2[0] * camera_matrix2[9] - camera_matrix2[5]\n",
    "    A[3][2] = p2[0] * camera_matrix2[10] - camera_matrix2[6]\n",
    "\n",
    "    d = np.zeros((1, 4))\n",
    "    d[0][0] = p1[0] * camera_matrix1[11] - camera_matrix1[3]\n",
    "    d[0][1] = p1[1] * camera_matrix1[11] - camera_matrix1[7]\n",
    "    d[0][2] = p2[0] * camera_matrix2[11] - camera_matrix2[3]\n",
    "    d[0][3] = p2[1] * camera_matrix2[11] - camera_matrix2[7]\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    # Calculate the pseudoinverse of S\n",
    "    S_pseudo = np.zeros(A.shape).T\n",
    "    S_pseudo[:S.shape[0], :S.shape[0]] = np.diag(1 / S)\n",
    "    # Calculate the pseudoinverse of A using SVD\n",
    "    A_pseudo = np.dot(np.dot(Vt.T, S_pseudo), U.T)\n",
    "\n",
    "    # Solve for matrix X\n",
    "    X = np.dot(A_pseudo, d.T)\n",
    "\n",
    "    return X\n",
    "\n",
    "M1 = camera_calibration(points1, points_3d)\n",
    "M2 = camera_calibration(points2, points_3d)\n",
    "F = calculate_fundamental_matrix(im1, im2)\n",
    "\n",
    "def click_and_mark(event, x, y, flags, param):\n",
    "    global points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        #points = (x, y)\n",
    "        cv2.circle(im1, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow('Image1', im1)# Mark the clicked point with a red circle\n",
    "\n",
    "        p_ = drawEpipolarLine(x, y, F, im1, im2)\n",
    "        print('3D Reconstruction: {}'.format(three_dimensional_reconstruction(M1, M2, (x, y), p_)))\n",
    "\n",
    "\n",
    "cv2.imshow('Image1', im1)\n",
    "cv2.setMouseCallback('Image1', click_and_mark)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # Press 'q' to quit and save the points\n",
    "    if key == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m points_2d_left\n\u001b[0;32m----> 6\u001b[0m ret, M1, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera(world_points, points_2d_left, img1\u001b[39m.\u001b[39mshape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m ret, M2, dist, rvecs, tvecs \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcalibrateCamera(world_points, points_2d_right, img2\u001b[39m.\u001b[39mshape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img1' is not defined"
     ]
    }
   ],
   "source": [
    "points_2d_left\n",
    "img1 = cv2.imread('im1.jpeg')\n",
    "im2 = cv2.imread('im2.jpeg')\n",
    "\n",
    "ret, M1, dist, rvecs, tvecs = cv2.calibrateCamera(world_points, points_2d_left, img1.shape[::-1], None, None)\n",
    "ret, M2, dist, rvecs, tvecs = cv2.calibrateCamera(world_points, points_2d_right, img2.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
